# Comandos de Limpeza - ReferÃªncia RÃ¡pida

## âœ… Resposta Direta

**Para limpar ETL sem apagar data/raw:**

```bash
make clean-data
```

---

## ðŸ“‹ Todos os Comandos

### 1. `make clean` (limpeza leve)

Remove apenas caches e arquivos compilados:

- `__pycache__/` (Python bytecode)
- `.ipynb_checkpoints/` (Jupyter checkpoints)
- `*.pyc` (compiled Python)
- `*.log` (log files)

**MantÃ©m:**

- `data/raw/` âœ…
- `data/etl/` âœ…
- CÃ³digo-fonte âœ…

**Uso:** Limpeza rÃ¡pida de cache sem afetar dados

```bash
make clean
```

---

### 2. `make clean-data` (limpeza de pipeline) â­ MAIS COMUM

Remove TODOS os dados processados:

- `data/etl/` (extracted, joined, features, labels)
- `data/ai/` (modelos e resultados)
- `notebooks/outputs/`
- `logs/`, `backups/`, `processed/`

**MantÃ©m:**

- `data/raw/` âœ… IMPORTANTE
- CÃ³digo-fonte âœ…
- Scripts âœ…

**Uso:** Resetar pipeline para re-executar do zero

```bash
make clean-data

# Depois re-executar pipeline
make extract PID=P000001 SNAPSHOT=2025-11-07 ZEPP_ZIP_PASSWORD=pLOeJaNn
make biomarkers PID=P000001 SNAPSHOT=2025-11-07
make labels PID=P000001 SNAPSHOT=2025-11-07
make nb2 PID=P000001 SNAPSHOT=2025-11-07
```

---

### 3. `make clean-provenance` (limpeza de metadados)

Remove arquivos transitÃ³rios de provenance:

- `pip_freeze_*.txt` (histÃ³rico de dependÃªncias)
- `hash_snapshot_*.json` (hashes de snapshots)
- `migrate_layout_*.json` (histÃ³rico de migraÃ§Ãµes)
- `cleanup_log_*.txt` (logs de limpeza)

**MantÃ©m:**

- `data/etl/` âœ…
- `data/raw/` âœ…
- `provenance/reports/` (relatÃ³rios importantes) âœ…

**Uso:** Limpar arquivos transitÃ³rios mantendo dados e relatÃ³rios

```bash
make clean-provenance
```

---

### 4. `make clean-all` (limpeza completa)

Remove TUDO (= clean + clean-data + clean-provenance):

- Caches Python
- Todos os dados processados (ETL outputs, AI models)
- Arquivos transitÃ³rios de provenance

**MantÃ©m:**

- `data/raw/` âœ… IMPORTANTE
- CÃ³digo-fonte âœ…
- DocumentaÃ§Ã£o âœ…

**Uso:** Limpeza profunda antes de experimento novo ou arquivamento

```bash
make clean-all

# Depois re-executar pipeline de zero
make extract PID=P000001 SNAPSHOT=2025-11-07 ZEPP_ZIP_PASSWORD=pLOeJaNn
# ... etc
```

---

## ðŸ“Š Matriz de DecisÃ£o

| Comando                 | Cache | data/raw | data/etl | data/ai | Provenance | Uso                 |
| ----------------------- | ----- | -------- | -------- | ------- | ---------- | ------------------- |
| `make clean`            | âŒ    | âœ…       | âœ…       | âœ…      | âœ…         | Cache local         |
| `make clean-data`       | âœ…    | âœ…       | âŒ       | âŒ      | âœ…         | Resetar pipeline    |
| `make clean-provenance` | âœ…    | âœ…       | âœ…       | âœ…      | âŒ         | Limpeza transitÃ³ria |
| `make clean-all`        | âŒ    | âœ…       | âŒ       | âŒ      | âŒ         | Limpeza total       |

---

## ðŸŽ¯ CenÃ¡rios PrÃ¡ticos

### CenÃ¡rio 1: Resetar pipeline (falhou em algum passo)

```bash
$ make clean-data
$ make extract PID=P000001 SNAPSHOT=2025-11-07 ZEPP_ZIP_PASSWORD=pLOeJaNn
$ make biomarkers PID=P000001 SNAPSHOT=2025-11-07
$ make labels PID=P000001 SNAPSHOT=2025-11-07
$ make nb2 PID=P000001 SNAPSHOT=2025-11-07
```

### CenÃ¡rio 2: Novo experimento com novos dados

```bash
$ make clean-all
# Copiar novos dados para data/raw/
$ make extract PID=P000002 SNAPSHOT=2025-11-15 ZEPP_ZIP_PASSWORD=pLOeJaNn
$ make pipeline PID=P000002 SNAPSHOT=2025-11-15
```

### CenÃ¡rio 3: Limpeza rÃ¡pida de cache (sem afetar dados)

```bash
$ make clean
# Continua com pipeline normalmente
$ make biomarkers PID=P000001 SNAPSHOT=2025-11-07
```

### CenÃ¡rio 4: Arquivar projeto (manter apenas dados brutos)

```bash
$ make clean-all
# Comprimir data/raw/ e arquivar
$ tar -czf backup_raw_data.tar.gz data/raw/
```

---

## ðŸ“ Estrutura de DiretÃ³rios Afetada

```
projeto/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    â† âœ… NUNCA apagado
â”‚   â”‚   â”œâ”€â”€ P000001/
â”‚   â”‚   â”‚   â”œâ”€â”€ apple/export/apple.zip
â”‚   â”‚   â”‚   â””â”€â”€ zepp/zepp.zip
â”‚   â”‚   â””â”€â”€ P000002/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ etl/                    â† âŒ Apagado por clean-data
â”‚   â”‚   â”œâ”€â”€ P000001/
â”‚   â”‚   â”‚   â””â”€â”€ 2025-11-07/
â”‚   â”‚   â”‚       â”œâ”€â”€ extracted/
â”‚   â”‚   â”‚       â””â”€â”€ joined/
â”‚   â”‚   â””â”€â”€ P000002/
â”‚   â”‚
â”‚   â””â”€â”€ ai/                     â† âŒ Apagado por clean-data
â”‚       â””â”€â”€ ... (modelos, resultados)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ outputs/                â† âŒ Apagado por clean-data
â”‚
â”œâ”€â”€ logs/                       â† âŒ Apagado por clean-data
â”œâ”€â”€ backups/                    â† âŒ Apagado por clean-data
â”œâ”€â”€ processed/                  â† âŒ Apagado por clean-data
â”‚
â”œâ”€â”€ __pycache__/                â† âŒ Apagado por clean
â”œâ”€â”€ .ipynb_checkpoints/         â† âŒ Apagado por clean
â”‚
â”œâ”€â”€ provenance/                 â† Parcialmente apagado por clean-all
â”‚   â”œâ”€â”€ *_transient*.json       â† âŒ Apagado por clean-provenance
â”‚   â””â”€â”€ reports/                â† âœ… MANTIDO
â”‚
â”œâ”€â”€ src/                        â† âœ… NUNCA apagado
â”œâ”€â”€ scripts/                    â† âœ… NUNCA apagado
â”œâ”€â”€ docs/                       â† âœ… NUNCA apagado
â””â”€â”€ Makefile                    â† âœ… NUNCA apagado
```

---

## âš ï¸ Pontos Importantes

1. **data/raw/ Ã© SEMPRE preservado**

   - Nenhum comando `make clean*` remove dados brutos
   - Ã‰ seguro limpar com confianÃ§a

2. **data/etl/ Ã© REMOVIDO completamente por clean-data**

   - Todos os CSVs processados desaparecem
   - Inclui extracted/, joined/, features/, labels/, etc.
   - PrecisarÃ¡ re-executar pipeline completo

3. **Use clean-all antes de experimentos novos**

   - Garante estado limpo
   - Evita mistura de dados de diferentes runs

4. **data/raw/ Ã© backup seguro**
   - Pode usar `make clean-all` sem medo
   - Dados brutos sempre podem ser re-processados

---

## ðŸ”§ ImplementaÃ§Ã£o (Makefile)

```makefile
# -------- Clean-up (safe, portable) --------
.PHONY: clean clean-data clean-provenance clean-all

clean:
	echo ">>> clean: removing caches and logs"
	find . -name "__pycache__" -type d -prune -exec rm -rf {} + 2>/dev/null || true
	find . -name ".ipynb_checkpoints" -type d -prune -exec rm -rf {} + 2>/dev/null || true
	find . -name "*.pyc" -delete 2>/dev/null || true
	find . -name "*.log" -delete 2>/dev/null || true
	echo "[OK] caches/logs removed"

clean-data:
	echo ">>> clean-data: removing ETL outputs and AI results"
	rm -rf notebooks/outputs dist/assets logs backups processed 2>/dev/null || true
	rm -rf data/etl data/ai 2>/dev/null || true
	echo "[OK] data outputs removed"

clean-provenance:
	echo ">>> clean-provenance: removing transient provenance artifacts (keep reports)"
	find provenance -type f \( \
	  -name "pip_freeze_*.txt" -o \
	  -name "hash_snapshot_*.json" -o \
	  -name "migrate_layout_*.json" -o \
	  -name "cleanup_log_*.txt" \
	\) -exec rm -f {} + 2>/dev/null || true
	echo "[OK] provenance transient files removed"

clean-all: clean clean-data clean-provenance
	echo ">>> clean-all: full cleanup done"
```
