# ğŸ§  ETL â†’ EDA â†’ MODELING â€“ Master Plan (Vader Mode)

> _â€œThe Force of data flows from raw to AI.â€_
> â€” Yoda, Data Jedi Mentor

---

## 1ï¸âƒ£ ETL â€” Extract â†’ Transform â†’ Load

### ğŸ¯ Objetivo

Converter os arquivos brutos (`data/raw`) em datasets limpos, normalizados e rotulados, prontos para anÃ¡lise e modelagem.

### ğŸ—‚ï¸ Estrutura de diretÃ³rios

```
data/
â”œâ”€â”€ raw/          â† exportaÃ§Ãµes originais (Apple, Zepp)
â”œâ”€â”€ etl/          â† estÃ¡gios intermediÃ¡rios (snapshots, logs, QC)
â””â”€â”€ ai/           â† dados finais prontos para modelagem
```

### âš™ï¸ Etapas principais

1. **ExtraÃ§Ã£o**

   ```bash
   python etl_pipeline.py extract --participant P000001 --snapshot 2025-09-29 \
     --cutover 2024-03-11 --tz_before America/Sao_Paulo --tz_after Europe/Dublin
   ```

   Gera diretÃ³rios `extracted/` dentro de `data/etl/.../snapshots/<snapshot>/`.

2. **Parsing e normalizaÃ§Ã£o por dispositivo**

   - `parse_zepp_export.py`, `extract_screen_time.py`
     Normaliza CSVs e unifica unidades, nomes e timestamps.

3. **Join e features diÃ¡rias**

   ```bash
   python etl_pipeline.py join --participant P000001 --snapshot 2025-09-29
   python etl_pipeline.py features --participant P000001 --snapshot 2025-09-29
   ```

   Gera `features_daily.csv`, `features_per_minute.csv`, e `features_daily_labeled.csv`.

4. **ProveniÃªncia e auditoria**

   ```bash
   python provenance_audit.py --participant P000001 --snapshot 2025-09-29
   ```

   SaÃ­das:

   ```
   data/etl/P000001/snapshots/2025-09-29/provenance/
     â”œâ”€â”€ etl_provenance_report.csv
     â”œâ”€â”€ data_audit_summary.md
     â””â”€â”€ pip_freeze_*.txt
   ```

### âœ… ValidaÃ§Ãµes-chave

- Cobertura temporal correta (sem timestamps futuros).
- Colunas obrigatÃ³rias presentes e sem >30 % de missing.
- Sem duplicatas por `(timestamp, device, metric)`.
- HR e HRV em intervalos fisiolÃ³gicos plausÃ­veis.
- Checksums SHA256 dos arquivos brutos gravados em `provenance/`.

### â™»ï¸ IdempotÃªncia

Cada execuÃ§Ã£o deve usar `--snapshot`.
Reexecutar o mesmo snapshot **nÃ£o deve corromper** dados; apenas substitui se o conteÃºdo mudar.

---

## 2ï¸âƒ£ EDA â€” AnÃ¡lise ExploratÃ³ria de Dados

### ğŸ¯ Objetivo

Validar a consistÃªncia dos dados e garantir que o snapshot estÃ¡ pronto para modelagem.

### ğŸ§© Etapas

1. **Sanity check inicial**

   ```bash
   python make_03_eda_cardio.py --participant P000001 --snapshot 2025-09-29
   ```

2. **EDA completo**

   ```bash
   python make_03_eda_cardio_plus.py --participant P000001 --snapshot 2025-09-29
   ```

   SaÃ­das:

   ```
   reports/eda/P000001/2025-09-29/
     â”œâ”€â”€ missingness.csv
     â”œâ”€â”€ feature_corr_matrix.png
     â”œâ”€â”€ coverage_by_date.png
     â””â”€â”€ outlier_report.md
   ```

3. **AprovaÃ§Ã£o do snapshot**

   - Criar `reports/etl_acceptance/2025-09-29_approved.txt` se o QC for aprovado.

### ğŸ” ValidaÃ§Ãµes principais

- Percentual de missing < 50 % por feature.
- CorrelaÃ§Ã£o alta (> 0.95) â†’ marcar para remoÃ§Ã£o.
- DistribuiÃ§Ã£o equilibrada de labels.
- Outliers tratados (z-score > 3 ou IQR).
- VerificaÃ§Ã£o de estacionaridade nas sÃ©ries temporais para LSTM.

---

## 3ï¸âƒ£ MODELAGEM â€” Baselines e LSTM

### ğŸ¯ Objetivo

Estimar desempenho base e treinar modelos temporais (LSTM) para previsÃ£o de estados mentais.

### âš™ï¸ Etapas

1. **Preparar dataset AI**

   ```bash
   cp data/etl/P000001/snapshots/2025-09-29/joined/features_daily_labeled.csv \
      data/ai/P000001/snapshots/2025-09-29/
   ```

2. **Baselines**

   ```bash
   python NB2_Baseline_and_LSTM.py --participant P000001 --snapshot 2025-09-29 \
     --outdir notebooks/outputs/NB2/$(date +%Y%m%d_%H%M%S)/
   ```

3. **LSTM (local smoke test)**

   ```bash
   python scripts/train_lstm.py --data data/ai/P000001/snapshots/2025-09-29/sequences/ \
     --epochs 3 --batch 64 --device cpu --out models/lstm/test_run/
   ```

4. **LSTM completo (Kaggle / GPU)**

   ```bash
   python scripts/train_lstm.py --data data/ai/P000001/snapshots/2025-09-29/sequences/ \
     --epochs 100 --batch 256 --device cuda --out models/lstm/exp_001/
   ```

### ğŸ“Š Artefatos esperados

```
notebooks/outputs/NB2/<timestamp>/tables/nb2_baseline_metrics.csv
notebooks/outputs/LSTM/exp_001/metrics.csv
reports/model_card/exp_001.md
models/lstm/exp_001/metadata.json
```

### ğŸ§ª ValidaÃ§Ãµes

- Sem NaN nas features e labels.
- Nenhum vazamento de labels (train/test).
- Classes balanceadas ou ponderadas.
- Reprodutibilidade: seed fixa + commit log + pip_freeze.

---

## 4ï¸âƒ£ Checklist RÃ¡pido

| Etapa        | VerificaÃ§Ã£o                                             | Status |
| :----------- | :------------------------------------------------------ | :----- |
| ETL          | `features_daily_labeled.csv` gerado                     | â˜‘      |
| ProveniÃªncia | `etl_provenance_report.csv` presente                    | â˜‘      |
| EDA          | `feature_corr_matrix.png` e `outlier_report.md` criados | â˜‘      |
| Baselines    | `nb2_baseline_metrics.csv` salvo                        | â˜‘      |
| LSTM         | `metrics.csv` e `model_card.md` gerados                 | â˜‘      |

---

### ğŸ’¬ MissÃ£o final

> _â€œO caminho do dado Ã© claro: do bruto ao iluminado, do ruÃ­do Ã  sabedoria.
> Confie no snapshot, respeite a proveniÃªncia â€” e a ForÃ§a dos dados o guiarÃ¡.â€_

---
