# ETL Stage Map

> **Source of Truth**: `scripts/run_full_pipeline.py`  
> **Generated**: 2025-12-08  
> **Method**: Code inspection only (no assumptions)

---

| Stage ID    | Module / Function                                            | Description (from code only)                                                                                                                                                                                                                                                                                                                                                                               | Main Inputs                                                                                               | Main Outputs                                                                                                                                                                            | Domains / Vendors Touched                                                                                                                                  | Dependencies / Notes                                                                                                                     |
| ----------- | ------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **Stage 0** | `run_full_pipeline.py` → `stage_0_ingest()`                  | **Ingest**: Extracts ZIP files from `data/raw/` to `data/etl/.../extracted/`. Apple export ZIPs, Apple Auto Export ZIPs (deterministic selection based on filename date ≤ snapshot), and Zepp ZIPs (optional, requires password).                                                                                                                                                                          | `data/raw/<PID>/apple/export/*.zip`, `data/raw/<PID>/apple/autoexport/*.zip`, `data/raw/<PID>/zepp/*.zip` | `extracted/apple/`, `extracted/apple/autoexport/`, `extracted/zepp/`                                                                                                                    | **Vendors**: apple_export, apple_autoexport, zepp_cloud                                                                                                    | Zepp extraction is optional (skipped if no password). AutoExport ZIP selected by filename date ≤ snapshot for determinism.               |
| **Stage 1** | `src/etl/stage_csv_aggregation.py` → `run_csv_aggregation()` | **Aggregate**: Parses Apple `export.xml` and Zepp CSVs to produce daily aggregated metrics. Uses `AppleHealthAggregator` and `ZeppHealthAggregator` classes. Writes `daily_sleep.csv`, `daily_cardio.csv`, `daily_activity.csv` per vendor.                                                                                                                                                                | `extracted/apple/apple_health_export/export.xml`, `extracted/zepp/*.csv`                                  | `extracted/apple/daily_sleep.csv`, `extracted/apple/daily_cardio.csv`, `extracted/apple/daily_activity.csv`, `extracted/zepp/daily_*.csv`                                               | **Domains**: sleep, cardio, activity. **Vendors**: apple_export, zepp_cloud                                                                                | Reads from `extracted/`. Does NOT process AutoExport CSVs or domains meds/som.                                                           |
| **Stage 2** | `src/etl/stage_unify_daily.py` → `run_unify_daily()`         | **Unify**: Merges Apple + Zepp daily CSVs into a single unified dataset with period expansion. Uses `DailyUnifier` class with methods `unify_sleep()`, `unify_cardio()`, `unify_activity()`, `unify_meds()`, `unify_som()`. Prefers Apple data when both vendors have data for same date.                                                                                                                  | `extracted/apple/daily_*.csv`, `extracted/zepp/daily_*.csv`                                               | `joined/features_daily_unified.csv`                                                                                                                                                     | **Domains**: sleep, cardio, activity, meds, som. **Vendors**: apple_export, apple_autoexport (meds/som via `med_vendor`, `som_vendor` columns), zepp_cloud | Reads from `extracted/`. Writes to `joined/`. Meds and SoM domains include vendor tracking columns.                                      |
| **Stage 3** | `src/etl/stage_apply_labels.py` → `run_apply_labels()`       | **Label**: Applies PBSI (Physiological Biomarker State Index) mood labels to the unified dataset. Creates temporal segments for z-score normalization. Computes `pbsi_score` (composite: 0.40×sleep + 0.35×cardio + 0.25×activity), `label_3cls` (+1 regulated, 0 typical, -1 dysregulated), and `pbsi_quality`. Uses `PBSILabeler` class and imports `build_pbsi_labels` from `src/labels/build_pbsi.py`. | `joined/features_daily_unified.csv`, `config/label_rules.yaml`                                            | `joined/features_daily_labeled.csv`                                                                                                                                                     | **Domains**: sleep, cardio, activity (via PBSI subscores). No vendor-specific logic.                                                                       | Reads from `joined/`. Writes to `joined/`. Creates `segment_id` column for segment-wise normalization.                                   |
| **Stage 4** | `run_full_pipeline.py` → `stage_4_segment()`                 | **Segment**: Auto-segments the labeled dataset by time boundaries (month/year changes) and gaps (>1 day). Creates `segment_autolog.csv` with segment metadata (date_start, date_end, reason, count, duration_days).                                                                                                                                                                                        | `features_daily_labeled.csv` (in memory from Stage 3)                                                     | `segment_autolog.csv`                                                                                                                                                                   | No domain/vendor specificity.                                                                                                                              | Inline implementation in pipeline script. Segments used for downstream ML analysis.                                                      |
| **Stage 5** | `run_full_pipeline.py` → `stage_5_prep_ml6()`                | **Prep ML6**: Prepares data for ML6 static classifier. (1) Temporal filter: keeps only dates ≥ 2021-05-11 (Amazfit GTR 2 era). (2) Removes anti-leak columns (pbsi_score, pbsi_quality, subscores). (3) MICE imputation (M=5, segment-aware using `IterativeImputer`). (4) Selects 10 feature columns for ML.                                                                                              | `features_daily_labeled.csv` (in memory)                                                                  | `ai/local/<PID>/<SNAPSHOT>/ml6/features_daily_ml6.csv`                                                                                                                                  | **Domains**: sleep, cardio, activity (10 selected features). No vendor columns in output.                                                                  | Inline implementation. Writes to `ai/local/` directory (not `data/etl/`). Anti-leak assertion checks.                                    |
| **Stage 6** | `run_full_pipeline.py` → `stage_6_ml6()`                     | **ML6 Training**: Trains LogisticRegression classifier with 6-fold temporal calendar CV (4mo train / 2mo val). Uses `create_calendar_folds()` from `src/etl/ml7_analysis.py`. Computes F1-macro and balanced accuracy per fold.                                                                                                                                                                            | `features_daily_ml6.csv` (in memory from Stage 5)                                                         | `ai/local/<PID>/<SNAPSHOT>/ml6/cv_summary.json`                                                                                                                                         | No domain/vendor specificity. ML on generic features.                                                                                                      | Uses `sklearn.linear_model.LogisticRegression`. Skipped if classes too imbalanced.                                                       |
| **Stage 7** | `run_full_pipeline.py` → `stage_7_ml7()`                     | **ML7 Analysis**: Performs SHAP interpretability, drift detection (ADWIN + KS), and LSTM training. Uses z-scored canonical features (`ML7_FEATURE_COLS`: 7 features). Imports `compute_shap_values`, `detect_drift_adwin`, `detect_drift_ks_segments`, `create_lstm_sequences`, `train_lstm_model` from `src/etl/ml7_analysis.py`. LSTM architecture: LSTM(32) → Dense(32) → Dropout(0.2) → Softmax.       | `features_daily_ml6.csv`                                                                                  | `ai/local/<PID>/<SNAPSHOT>/ml7/shap/`, `ai/local/<PID>/<SNAPSHOT>/ml7/drift_report.md`, `ai/local/<PID>/<SNAPSHOT>/ml7/lstm_report.md`, `ai/local/<PID>/<SNAPSHOT>/ml7/shap_summary.md` | **Domains**: sleep, cardio, activity (via z-scored features). No vendor columns.                                                                           | Drift detection on `pbsi_score` is skipped in current implementation (score not in z-scored dataset). LSTM uses 14-day sequence windows. |
| **Stage 8** | `run_full_pipeline.py` → `stage_8_tflite()`                  | **TFLite Export**: Converts best LSTM model to TensorFlow Lite format and measures inference latency (100 runs, p95). Uses `convert_to_tflite()` and `measure_latency()` from `src/etl/ml7_analysis.py`.                                                                                                                                                                                                   | Best LSTM model from Stage 7 (in memory)                                                                  | `ai/local/<PID>/<SNAPSHOT>/ml7/models/best_model.tflite`, `ai/local/<PID>/<SNAPSHOT>/ml7/latency_stats.json`                                                                            | No domain/vendor specificity.                                                                                                                              | Skipped if no LSTM model available from Stage 7.                                                                                         |
| **Stage 9** | `run_full_pipeline.py` → `stage_9_report()`                  | **Generate Report**: Creates `RUN_REPORT.md` summarizing pipeline results: data summary, label distribution, ML6 CV results, SHAP top features, drift detection results, LSTM results, TFLite latency, and artifact paths.                                                                                                                                                                                 | All pipeline context results, `features_daily_labeled.csv`, `cv_summary.json`                             | `RUN_REPORT.md` (in repository root)                                                                                                                                                    | No domain/vendor specificity. Summary only.                                                                                                                | Final stage. Aggregates results from all previous stages.                                                                                |

---

## Summary

This ETL pipeline consists of **10 stages (0-9)**:

1. **Stages 0-2** (Ingest → Aggregate → Unify): Raw data extraction and multi-vendor daily aggregation. Touches vendors `apple_export`, `apple_autoexport`, `zepp_cloud` and domains `sleep`, `cardio`, `activity`, `meds`, `som`.

2. **Stage 3** (Label): Applies PBSI mood labels with segment-wise z-score normalization. Domain-agnostic composite scoring.

3. **Stages 4-8** (Segment → Prep → ML6 → ML7 → TFLite): ML pipeline with temporal filtering (≥2021-05-11), MICE imputation, LogisticRegression baseline, LSTM sequence classifier, SHAP interpretability, and TFLite export.

4. **Stage 9** (Report): Generates human-readable summary of all results.

**Key Observations from Code**:

- Stage 1 (`stage_csv_aggregation.py`) does NOT process AutoExport CSVs or meds/som domains
- Meds and SoM domain processing happens via separate domain modules called during Stage 2 unification
- Vendor tracking (`med_vendor`, `som_vendor`) is added during Stage 2 unification
- All ML stages (5-8) write to `ai/local/` directory, not `data/etl/`
