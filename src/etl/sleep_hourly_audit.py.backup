#!/usr/bin/env python3
"""
Sleep Hourly Audit Module

Purpose: Distinguish "real sleepless nights" from "sensor/device missing" days
by analyzing hourly-level heart rate and activity data alongside sleep records.

Usage:
    python -m src.etl.sleep_hourly_audit P000001 2025-11-07

Author: PhD-level Data Engineer
Date: 2025-11-19
"""

import argparse
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import xml.etree.ElementTree as ET

import pandas as pd
import numpy as np

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)


class SleepHourlyAuditor:
    """
    Audit sleep data at hourly resolution to distinguish:
    1. Real sleepless nights (awake all night, sensors active)
    2. Sensor missing days (no sleep + no HR + no steps)
    3. Normal sleep nights
    4. Ambiguous days (unclear classification)
    """
    
    # Classification thresholds
    MIN_SLEEP_HOURS = 3.0  # Below this = sleepless
    MIN_HR_RECORDS_OVERNIGHT = 10  # Min HR records to consider "sensor active"
    MIN_STEPS_OVERNIGHT = 5  # Min steps to consider "activity recorded"
    
    # Overnight window (for checking HR/steps during sleep hours)
    OVERNIGHT_START_HOUR = 22  # 10 PM
    OVERNIGHT_END_HOUR = 8     # 8 AM
    
    def __init__(self, participant_id: str, snapshot: str):
        """Initialize auditor for given participant/snapshot."""
        self.participant_id = participant_id
        self.snapshot = snapshot
        
        # Paths
        self.data_root = Path("data")
        self.etl_dir = self.data_root / "etl" / participant_id / snapshot
        self.extracted_dir = self.etl_dir / "extracted"
        self.qc_dir = self.data_root / "ai" / participant_id / snapshot / "qc"
        self.qc_dir.mkdir(parents=True, exist_ok=True)
        
        # Data containers
        self.daily_sleep = None
        self.hourly_hr = None
        self.hourly_steps = None
        
        # Audit date range (set by run_audit)
        self.audit_start_dt = None
        self.audit_end_dt = None
        
    def load_data(self):
        """Load sleep, HR, and steps data from extracted layer."""
        logger.info(f"Loading data for {self.participant_id}/{self.snapshot}...")
        
        # Determine date window for loading (expand by 1 day for overnight windows)
        start_dt = self.audit_start_dt - pd.Timedelta(days=1) if self.audit_start_dt else None
        end_dt = self.audit_end_dt + pd.Timedelta(days=1) if self.audit_end_dt else None
        
        if start_dt and end_dt:
            logger.info(f"  Loading data window: {start_dt.date()} to {end_dt.date()} (±1 day buffer)")
        
        # Load daily sleep aggregates
        sleep_path = self.extracted_dir / "apple" / "daily_sleep.csv"
        if sleep_path.exists():
            self.daily_sleep = pd.read_csv(sleep_path)
            self.daily_sleep["date"] = pd.to_datetime(self.daily_sleep["date"])
            
            # Filter to date range if specified
            if start_dt and end_dt:
                original_len = len(self.daily_sleep)
                self.daily_sleep = self.daily_sleep[
                    (self.daily_sleep["date"] >= start_dt) & 
                    (self.daily_sleep["date"] <= end_dt)
                ].copy()
                logger.info(f"  Loaded daily sleep: {len(self.daily_sleep)} days (filtered from {original_len})")
            else:
                logger.info(f"  Loaded daily sleep: {len(self.daily_sleep)} days")
        else:
            logger.warning(f"  Daily sleep not found: {sleep_path}")
            self.daily_sleep = pd.DataFrame(columns=["date", "sleep_hours"])
        
        # Load hourly HR and steps from export.xml using streaming parser
        xml_path = self.extracted_dir / "apple" / "apple_health_export" / "export.xml"
        if xml_path.exists():
            logger.info(f"  Parsing export.xml for hourly data (streaming mode)...")
            self._parse_hourly_data(xml_path, start_date=start_dt, end_date=end_dt)
        else:
            logger.warning(f"  export.xml not found: {xml_path}")
            self.hourly_hr = pd.DataFrame(columns=["datetime", "hr"])
            self.hourly_steps = pd.DataFrame(columns=["datetime", "steps"])
    
    def _parse_hourly_data(self, xml_path: Path, start_date: Optional[pd.Timestamp] = None, 
                          end_date: Optional[pd.Timestamp] = None):
        """
        Parse export.xml to extract hourly HR and steps using streaming iterparse.
        
        Args:
            xml_path: Path to export.xml
            start_date: Optional start date for filtering (inclusive)
            end_date: Optional end date for filtering (inclusive)
        """
        hr_records = []
        step_records = []
        
        # Counters for logging
        hr_total = 0
        hr_filtered = 0
        steps_total = 0
        steps_filtered = 0
        
        # Use iterparse for streaming (memory-efficient)
        context = ET.iterparse(xml_path, events=("end",))
        
        for event, elem in context:
            if elem.tag != "Record":
                continue
            
            record_type = elem.get("type")
            
            # Parse HR records
            if record_type == "HKQuantityTypeIdentifierHeartRate":
                hr_total += 1
                try:
                    dt_str = elem.get("startDate")
                    value_str = elem.get("value")
                    
                    if dt_str is None or value_str is None:
                        continue
                    
                    value = float(value_str)
                    dt = pd.to_datetime(dt_str)
                    
                    # Filter by date range if specified
                    if start_date is not None and dt < start_date:
                        elem.clear()
                        continue
                    if end_date is not None and dt > end_date:
                        elem.clear()
                        continue
                    
                    hr_records.append({"datetime": dt, "hr": value})
                    hr_filtered += 1
                except (ValueError, TypeError):
                    pass
                
                # Clear element to free memory
                elem.clear()
            
            # Parse step records
            elif record_type == "HKQuantityTypeIdentifierStepCount":
                steps_total += 1
                try:
                    dt_str = elem.get("startDate")
                    value_str = elem.get("value")
                    
                    if dt_str is None or value_str is None:
                        continue
                    
                    value = float(value_str)
                    dt = pd.to_datetime(dt_str)
                    
                    # Filter by date range if specified
                    if start_date is not None and dt < start_date:
                        elem.clear()
                        continue
                    if end_date is not None and dt > end_date:
                        elem.clear()
                        continue
                    
                    step_records.append({"datetime": dt, "steps": value})
                    steps_filtered += 1
                except (ValueError, TypeError):
                    pass
                
                # Clear element to free memory
                elem.clear()
            else:
                # Clear unneeded elements
                elem.clear()
        
        # Build DataFrames
        self.hourly_hr = pd.DataFrame(hr_records)
        self.hourly_steps = pd.DataFrame(step_records)
        
        if start_date or end_date:
            logger.info(f"    HR records: {hr_filtered:,} (filtered from {hr_total:,})")
            logger.info(f"    Step records: {steps_filtered:,} (filtered from {steps_total:,})")
        else:
            logger.info(f"    HR records: {len(self.hourly_hr):,}")
            logger.info(f"    Step records: {len(self.hourly_steps):,}")
    
    def classify_day(self, date: pd.Timestamp) -> Dict:
        """
        Classify a single day as:
        - normal: sleep >= MIN_SLEEP_HOURS, HR/steps present
        - sleepless: sleep < MIN_SLEEP_HOURS, HR/steps present (real awake night)
        - sensor_missing: no sleep + no HR + no steps overnight
        - ambiguous: doesn't fit clear pattern
        
        Returns dict with classification and supporting evidence.
        """
        # Get sleep hours for this date
        if self.daily_sleep is not None and len(self.daily_sleep) > 0:
            sleep_row = self.daily_sleep[self.daily_sleep["date"] == date]
            sleep_hours = sleep_row["sleep_hours"].values[0] if len(sleep_row) > 0 else 0.0
        else:
            sleep_hours = 0.0
        
        # Define overnight window (previous evening to this morning)
        # E.g., for date 2023-10-05, check 2023-10-04 22:00 to 2023-10-05 08:00
        overnight_start = date - pd.Timedelta(hours=24-self.OVERNIGHT_START_HOUR)
        overnight_end = date + pd.Timedelta(hours=self.OVERNIGHT_END_HOUR)
        
        # Count HR records in overnight window
        if self.hourly_hr is not None and len(self.hourly_hr) > 0:
            hr_overnight = self.hourly_hr[
                (self.hourly_hr["datetime"] >= overnight_start) & 
                (self.hourly_hr["datetime"] <= overnight_end)
            ]
            hr_count = len(hr_overnight)
        else:
            hr_count = 0
        
        # Count steps in overnight window
        if self.hourly_steps is not None and len(self.hourly_steps) > 0:
            steps_overnight = self.hourly_steps[
                (self.hourly_steps["datetime"] >= overnight_start) & 
                (self.hourly_steps["datetime"] <= overnight_end)
            ]
            steps_count = steps_overnight["steps"].sum() if len(steps_overnight) > 0 else 0
        else:
            steps_count = 0
        
        # Classification logic
        has_sleep = sleep_hours >= self.MIN_SLEEP_HOURS
        has_hr = hr_count >= self.MIN_HR_RECORDS_OVERNIGHT
        has_steps = steps_count >= self.MIN_STEPS_OVERNIGHT
        has_sensor_activity = has_hr or has_steps
        
        if has_sleep and has_sensor_activity:
            classification = "normal"
        elif not has_sleep and has_sensor_activity:
            # Low sleep but sensors active = real sleepless night
            classification = "sleepless"
        elif not has_sleep and not has_sensor_activity:
            # No sleep and no sensor activity = device not worn
            classification = "sensor_missing"
        else:
            # Has sleep but no sensor activity = unusual (sleep recorded without HR/steps?)
            classification = "ambiguous"
        
        return {
            "date": date.strftime("%Y-%m-%d"),
            "classification": classification,
            "sleep_hours": sleep_hours,
            "hr_records_overnight": hr_count,
            "steps_overnight": int(steps_count),
            "has_sensor_activity": has_sensor_activity
        }
    
    def find_longest_sequences(self, df: pd.DataFrame, classification: str) -> Tuple[Optional[pd.Timestamp], Optional[pd.Timestamp], int]:
        """Find longest continuous sequence of given classification."""
        df_filtered = df[df["classification"] == classification].copy()
        
        if len(df_filtered) == 0:
            return None, None, 0
        
        df_filtered = df_filtered.sort_values("date")
        
        # Find gaps > 1 day
        df_filtered["date_dt"] = pd.to_datetime(df_filtered["date"])
        df_filtered["gap"] = (df_filtered["date_dt"] - df_filtered["date_dt"].shift(1)).dt.days
        
        # Mark sequence groups
        df_filtered["is_new_seq"] = (df_filtered["gap"].isna()) | (df_filtered["gap"] > 1)
        df_filtered["seq_id"] = df_filtered["is_new_seq"].cumsum()
        
        # Find longest sequence
        seq_lengths = df_filtered.groupby("seq_id").size()
        longest_seq_id = seq_lengths.idxmax()
        longest_seq = df_filtered[df_filtered["seq_id"] == longest_seq_id]
        
        start_date = longest_seq["date_dt"].min()
        end_date = longest_seq["date_dt"].max()
        length = len(longest_seq)
        
        return start_date, end_date, length
    
    def run_audit(self, start_date: str = "2023-01-01", end_date: Optional[str] = None) -> pd.DataFrame:
        """
        Run full audit over date range.
        
        Args:
            start_date: Start date for audit (YYYY-MM-DD)
            end_date: End date for audit (YYYY-MM-DD), defaults to last date in data
        
        Returns DataFrame with classification for each day.
        """
        # Convert dates to Timestamps and store as attributes
        self.audit_start_dt = pd.to_datetime(start_date)
        
        # Determine end date
        if end_date is None:
            # Will be set after loading data
            temp_end_dt = None
        else:
            temp_end_dt = pd.to_datetime(end_date)
        
        logger.info(f"Running audit from {start_date} to {end_date or 'last available date'}...")
        
        # Load data (this will use self.audit_start_dt and self.audit_end_dt if set)
        # For now, set a temporary end date for loading
        if temp_end_dt:
            self.audit_end_dt = temp_end_dt
        else:
            # Use a far future date to load all data, then determine actual end
            self.audit_end_dt = pd.to_datetime("2030-12-31")
        
        self.load_data()
        
        # Now determine actual end date from loaded data if not specified
        if end_date is None:
            max_dates = []
            if self.daily_sleep is not None and len(self.daily_sleep) > 0:
                max_dates.append(self.daily_sleep["date"].max())
            if self.hourly_hr is not None and len(self.hourly_hr) > 0:
                max_dates.append(self.hourly_hr["datetime"].max())
            if self.hourly_steps is not None and len(self.hourly_steps) > 0:
                max_dates.append(self.hourly_steps["datetime"].max())
            
            if max_dates:
                self.audit_end_dt = max(max_dates).normalize()  # Get date part
                logger.info(f"  End date determined from data: {self.audit_end_dt.date()}")
            else:
                self.audit_end_dt = pd.to_datetime("2025-10-21")
                logger.warning(f"  No data loaded, using default end date: {self.audit_end_dt.date()}")
        
        # Generate date range for classification
        date_range = pd.date_range(start=self.audit_start_dt, end=self.audit_end_dt, freq="D")
        
        # Classify each day
        logger.info(f"Classifying {len(date_range)} days...")
        results = []
        for date in date_range:
            result = self.classify_day(date)
            results.append(result)
        
        df = pd.DataFrame(results)
        df["date"] = pd.to_datetime(df["date"])
        
        logger.info(f"Classification complete: {len(df)} days")
        
        return df
    
    def generate_report(self, df: pd.DataFrame) -> str:
        """Generate markdown report from audit results."""
        
        # Count by classification
        counts = df["classification"].value_counts()
        total_days = len(df)
        
        # Find longest sequences
        sleepless_start, sleepless_end, sleepless_len = self.find_longest_sequences(df, "sleepless")
        sensor_start, sensor_end, sensor_len = self.find_longest_sequences(df, "sensor_missing")
        
        # Sample days for each classification
        samples = {}
        for classification in ["normal", "sleepless", "sensor_missing", "ambiguous"]:
            sample = df[df["classification"] == classification].sample(
                n=min(5, len(df[df["classification"] == classification])),
                random_state=42
            )
            samples[classification] = sample
        
        # Build report
        report = f"""# Sleep Hourly Audit Report

**Participant**: {self.participant_id}  
**Snapshot**: {self.snapshot}  
**Audit Date**: {datetime.now().strftime("%Y-%m-%d")}  
**Date Range**: {df["date"].min().strftime("%Y-%m-%d")} to {df["date"].max().strftime("%Y-%m-%d")}  
**Total Days**: {total_days}

---

## Classification Definitions

This audit distinguishes four types of days based on sleep duration and sensor activity:

1. **Normal Sleep** (`normal`):
   - Sleep duration ≥ {self.MIN_SLEEP_HOURS:.1f} hours
   - HR and/or steps recorded overnight (sensors active)
   - Interpretation: User slept normally with device worn

2. **Real Sleepless Nights** (`sleepless`):
   - Sleep duration < {self.MIN_SLEEP_HOURS:.1f} hours
   - HR and/or steps recorded overnight (sensors active)
   - Interpretation: User was genuinely awake/restless but device was worn
   - **This is a real physiological event, NOT missing data**

3. **Sensor Missing Days** (`sensor_missing`):
   - No sleep recorded (or sleep = 0)
   - No HR recorded overnight (< {self.MIN_HR_RECORDS_OVERNIGHT} records)
   - No steps recorded overnight (< {self.MIN_STEPS_OVERNIGHT} steps)
   - Interpretation: Device not worn or not recording
   - **This is missing data, NOT a sleepless night**

4. **Ambiguous Days** (`ambiguous`):
   - Doesn't fit clear pattern (e.g., sleep recorded but no HR/steps)
   - Interpretation: Unclear - may need manual review

**Overnight Window**: {self.OVERNIGHT_START_HOUR}:00 previous day to {self.OVERNIGHT_END_HOUR}:00 current day

---

## Summary Statistics

| Classification | Count | Percentage |
|---------------|-------|------------|
"""
        
        for classification in ["normal", "sleepless", "sensor_missing", "ambiguous"]:
            count = counts.get(classification, 0)
            pct = 100 * count / total_days if total_days > 0 else 0
            report += f"| **{classification}** | {count} | {pct:.1f}% |\n"
        
        report += f"\n**Total**: {total_days} days\n\n"
        
        report += """---

## Longest Continuous Sequences

"""
        
        if sleepless_len > 0:
            report += f"""### Longest Sleepless Sequence

- **Start Date**: {sleepless_start.strftime("%Y-%m-%d") if sleepless_start else "N/A"}
- **End Date**: {sleepless_end.strftime("%Y-%m-%d") if sleepless_end else "N/A"}
- **Length**: {sleepless_len} consecutive days
- **Interpretation**: Longest period of real sleepless nights (sensors active, low sleep)

"""
        else:
            report += "### Longest Sleepless Sequence\n\nNone found.\n\n"
        
        if sensor_len > 0:
            report += f"""### Longest Sensor Missing Sequence

- **Start Date**: {sensor_start.strftime("%Y-%m-%d") if sensor_start else "N/A"}
- **End Date**: {sensor_end.strftime("%Y-%m-%d") if sensor_end else "N/A"}
- **Length**: {sensor_len} consecutive days
- **Interpretation**: Longest period without device/sensor activity

"""
        else:
            report += "### Longest Sensor Missing Sequence\n\nNone found.\n\n"
        
        report += """---

## Sample Days

Below are sample days from each classification category:

"""
        
        for classification in ["normal", "sleepless", "sensor_missing", "ambiguous"]:
            report += f"### {classification.capitalize()} Days\n\n"
            
            sample = samples[classification]
            if len(sample) > 0:
                report += "| Date | Sleep Hours | HR Records Overnight | Steps Overnight |\n"
                report += "|------|-------------|---------------------|------------------|\n"
                
                for _, row in sample.iterrows():
                    report += f"| {row['date'].strftime('%Y-%m-%d')} | {row['sleep_hours']:.2f} | {row['hr_records_overnight']} | {row['steps_overnight']} |\n"
                
                report += "\n"
            else:
                report += "No days found in this category.\n\n"
        
        report += """---

## Interpretation Guidelines

### How to Use This Audit

1. **Sleepless vs Missing**: Use `classification` column to distinguish:
   - `sleepless`: Keep in dataset as real physiological event (low sleep, sensors active)
   - `sensor_missing`: Flag as missing data (consider excluding or imputing)

2. **PBSI Computation**: 
   - For sleepless days: Use sleep_hours ≈ 0 in PBSI (reflects real poor sleep)
   - For sensor_missing days: Treat as NaN (don't impute with previous day's sleep)

3. **Modeling**:
   - Sleepless days have predictive value (real low-sleep events)
   - Sensor missing days should be masked or handled as missing data

4. **Label Assignment**:
   - Sleepless nights may correlate with mood/symptom changes (real signal)
   - Sensor missing days should not be labeled (no ground truth)

### Validation Checks

**Expected Patterns**:
- Most days should be "normal" (typical usage)
- Sleepless nights should be sporadic (few per month)
- Sensor missing days may occur in clusters (forgot to charge, travel)

**Red Flags**:
- High percentage of ambiguous days (> 10%) → check classification logic
- Very long sensor missing sequences (> 30 days) → user may have stopped using device
- No sleepless nights found → classification threshold may be too strict

---

## Technical Notes

**Data Sources**:
- Daily sleep: `data/etl/{self.participant_id}/{self.snapshot}/extracted/apple/daily_sleep.csv`
- HR records: Parsed from `export.xml` (HKQuantityTypeIdentifierHeartRate)
- Steps records: Parsed from `export.xml` (HKQuantityTypeIdentifierStepCount)

**Classification Thresholds**:
- `MIN_SLEEP_HOURS`: {self.MIN_SLEEP_HOURS:.1f} hours
- `MIN_HR_RECORDS_OVERNIGHT`: {self.MIN_HR_RECORDS_OVERNIGHT} records
- `MIN_STEPS_OVERNIGHT`: {self.MIN_STEPS_OVERNIGHT} steps

**Overnight Window**:
- Start: {self.OVERNIGHT_START_HOUR}:00 (previous day)
- End: {self.OVERNIGHT_END_HOUR}:00 (current day)
- Rationale: Captures typical sleep period + late-night/early-morning activity

**Limitations**:
- Assumes local timezone (same as ETL daily aggregation)
- Hourly resolution limited by HealthKit export granularity
- Classification is heuristic-based (not ground truth)
- May misclassify naps or irregular sleep schedules

---

**Report Generated**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Auditor**: sleep_hourly_audit.py (v1.0)

"""
        
        return report
    
    def save_report(self, df: pd.DataFrame):
        """Save audit report and classification CSV."""
        # Generate markdown report
        report = self.generate_report(df)
        
        # Save report
        report_path = self.qc_dir / "sleep_hourly_audit.md"
        with open(report_path, "w") as f:
            f.write(report)
        logger.info(f"Report saved: {report_path}")
        
        # Save classification CSV
        csv_path = self.qc_dir / "sleep_classification.csv"
        df.to_csv(csv_path, index=False)
        logger.info(f"Classification CSV saved: {csv_path}")
    
    def print_summary(self, df: pd.DataFrame):
        """Print concise summary to stdout."""
        counts = df["classification"].value_counts()
        total = len(df)
        
        print("\n" + "="*60)
        print(f"SLEEP HOURLY AUDIT SUMMARY: {self.participant_id}/{self.snapshot}")
        print("="*60)
        print(f"Date Range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}")
        print(f"Total Days: {total}")
        print("\nClassification Counts:")
        for classification in ["normal", "sleepless", "sensor_missing", "ambiguous"]:
            count = counts.get(classification, 0)
            pct = 100 * count / total if total > 0 else 0
            print(f"  {classification:20s}: {count:5d} ({pct:5.1f}%)")
        
        # Longest sequences
        sleepless_start, sleepless_end, sleepless_len = self.find_longest_sequences(df, "sleepless")
        sensor_start, sensor_end, sensor_len = self.find_longest_sequences(df, "sensor_missing")
        
        print("\nLongest Sequences:")
        if sleepless_len > 0 and sleepless_start and sleepless_end:
            print(f"  Sleepless nights: {sleepless_len} days ({sleepless_start.strftime('%Y-%m-%d')} to {sleepless_end.strftime('%Y-%m-%d')})")
        else:
            print(f"  Sleepless nights: None found")
        
        if sensor_len > 0 and sensor_start and sensor_end:
            print(f"  Sensor missing: {sensor_len} days ({sensor_start.strftime('%Y-%m-%d')} to {sensor_end.strftime('%Y-%m-%d')})")
        else:
            print(f"  Sensor missing: None found")
        
        print("="*60 + "\n")


def main():
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Sleep Hourly Audit: Distinguish real sleepless nights from missing sensor data",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python -m src.etl.sleep_hourly_audit P000001 2025-11-07
  python -m src.etl.sleep_hourly_audit P000002 2025-10-22 --start-date 2024-01-01

Output:
  - Markdown report: data/ai/{PID}/{SNAPSHOT}/qc/sleep_hourly_audit.md
  - Classification CSV: data/ai/{PID}/{SNAPSHOT}/qc/sleep_classification.csv
        """
    )
    
    parser.add_argument("participant_id", help="Participant ID (e.g., P000001)")
    parser.add_argument("snapshot", help="Snapshot date (e.g., 2025-11-07)")
    parser.add_argument("--start-date", default="2023-01-01", help="Start date for audit (default: 2023-01-01)")
    parser.add_argument("--end-date", default=None, help="End date for audit (default: last date in extracted data)")
    
    args = parser.parse_args()
    
    # Initialize auditor
    auditor = SleepHourlyAuditor(args.participant_id, args.snapshot)
    
    # Load data
    try:
        auditor.load_data()
    except Exception as e:
        logger.error(f"Failed to load data: {e}")
        return 1
    
    # Run audit (end_date will be determined inside run_audit if not specified)
    try:
        df = auditor.run_audit(start_date=args.start_date, end_date=args.end_date)
    except Exception as e:
        logger.error(f"Failed to run audit: {e}")
        return 1
    
    # Print summary
    auditor.print_summary(df)
    
    # Save report
    try:
        auditor.save_report(df)
    except Exception as e:
        logger.error(f"Failed to save report: {e}")
        return 1
    
    logger.info("Audit completed successfully")
    return 0


if __name__ == "__main__":
    sys.exit(main())
