#!/usr/bin/env python3
"""Generate release notes markdown for a given version/tag.

Usage:
    make_scripts/release_notes.py --version X --tag vX [--outfile docs/release_notes/release_notes_vX.md] [--since-tag vY]

The script will:
  - Read docs/HIGHLIGHTS.md for a Highlights section if present
  - Collect git commits between --since-tag (or last tag) and --tag and group them by Conventional Commit type
  - List provenance artifacts and intake logs
  - Write a markdown file to --outfile (creates parent dir if needed)
"""

from __future__ import annotations
import argparse
import datetime
import re
import subprocess
import sys
from pathlib import Path
from typing import List, Dict


def run(cmd: List[str], cwd: Path = None) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=cwd)


def read_highlights() -> List[str]:
    p = Path('docs') / 'HIGHLIGHTS.md'
    if p.exists():
        return [line.rstrip('\n') for line in p.read_text(encoding='utf-8').splitlines() if line.strip()]
    # autogenerated small bullet list
    return ["Improved provenance auditing and layout tooling.", "Added intake + migration helpers and layout linters."]


CONVENTIONAL_TYPES = ['feat', 'fix', 'refactor', 'docs', 'chore']


def parse_git_log(since: str, until: str) -> List[Dict[str,str]]:
    # Use pretty format with subject and body separated by a null char
    fmt = '%H%x01%ad%x01%s%x01%b'
    args = ['git', 'log', '--date=short', f'--pretty=format:{fmt}', f'{since}..{until}']
    r = run(args)
    if r.returncode != 0:
        # If since..until fails (maybe tag missing), try to get last N commits up to until
        r = run(['git', 'log', '-n', '200', '--date=short', f'--pretty=format:{fmt}', until])
    lines = r.stdout.splitlines()
    commits = []
    for line in lines:
        parts = line.split('\x01')
        if len(parts) < 4:
            continue
        sha, date, subject, body = parts[0], parts[1], parts[2], parts[3]
        commits.append({'sha': sha, 'date': date, 'subject': subject, 'body': body})
    return commits


def group_commits(commits: List[Dict[str,str]]) -> Dict[str, List[Dict[str,str]]]:
    grouped: Dict[str, List[Dict[str,str]]] = {k: [] for k in CONVENTIONAL_TYPES}
    grouped['other'] = []
    re_cc = re.compile(r'^(?P<type>[^(:!]+)(?:\(.+?\))?:\s*(?P<desc>.+)$')
    for c in commits:
        m = re_cc.match(c['subject'])
        if m:
            t = m.group('type')
            desc = m.group('desc')
            key = t if t in CONVENTIONAL_TYPES else 'other'
            grouped.setdefault(key, []).append({'sha': c['sha'], 'date': c['date'], 'subject': desc})
        else:
            grouped['other'].append({'sha': c['sha'], 'date': c['date'], 'subject': c['subject']})
    return grouped


def find_artifacts(participant: str) -> Dict[str, List[str]]:
    artifacts = {}
    # provenance md files
    prov_md = list(Path('provenance').glob('*.md')) if Path('provenance').exists() else []
    artifacts['provenance_md'] = [str(p.as_posix()) for p in prov_md]
    # provenance csvs with provenance in name
    prov_csv = []
    if Path('provenance').exists():
        prov_csv = [p for p in Path('provenance').glob('*.csv') if 'provenance' in p.name or 'etl_provenance' in p.name]
    artifacts['provenance_csv'] = [str(p.as_posix()) for p in prov_csv]
    # latest pip freeze
    pip_freeze = []
    if Path('provenance').exists():
        pip_freeze = sorted(Path('provenance').glob('pip_freeze_*.txt'), key=lambda p: p.stat().st_mtime, reverse=True)
    artifacts['pip_freeze_latest'] = [str(p.as_posix()) for p in pip_freeze[:1]]
    # intake logs under data/etl/<participant>/runs/*/logs/intake_log.json
    intake_logs = list(Path('data') .glob(f'etl/{participant}/runs/*/logs/intake_log.json'))
    artifacts['intake_logs'] = [str(p.as_posix()) for p in intake_logs]
    return artifacts


def compose_md(version: str, tag: str, highlights: List[str], grouped: Dict[str, List[Dict[str,str]]], artifacts: Dict[str, List[str]], since_tag: str, participant: str) -> str:
    utcnow = datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')
    lines: List[str] = []
    lines.append(f"# Release {version} ({tag}) â€” {utcnow}")
    lines.append("")
    lines.append("## Highlights")
    lines.append("")
    if highlights:
        for h in highlights:
            lines.append(f"- {h}")
    else:
        lines.append("- Minor tooling and provenance improvements.")
    lines.append("")
    lines.append("## Changes")
    lines.append("")
    for t in CONVENTIONAL_TYPES + ['other']:
        items = grouped.get(t, [])
        if not items:
            continue
        lines.append(f"### {t}")
        lines.append("")
        for it in items:
            sha = it.get('sha','')[:7]
            date = it.get('date','')
            subj = it.get('subject','')
            lines.append(f"- {subj} ({sha} â€” {date})")
        lines.append("")
    lines.append("## Artifacts")
    lines.append("")
    if artifacts.get('provenance_md'):
        lines.append("Provenance markdown files:")
        for p in artifacts['provenance_md']:
            lines.append(f"- {p}")
        lines.append("")
    if artifacts.get('provenance_csv'):
        lines.append("Provenance CSV files:")
        for p in artifacts['provenance_csv']:
            lines.append(f"- {p}")
        lines.append("")
    if artifacts.get('pip_freeze_latest'):
        lines.append("Latest pip freeze:")
        for p in artifacts['pip_freeze_latest']:
            lines.append(f"- {p}")
        lines.append("")
    if artifacts.get('intake_logs'):
        lines.append(f"Intake logs for participant {participant}:")
        for p in artifacts['intake_logs']:
            lines.append(f"- {p}")
        lines.append("")
    lines.append("## Reproduce")
    lines.append("")
    lines.append("To reproduce common checks and run the ETL helpers:")
    lines.append("")
    lines.append("```sh")
    lines.append("make init-data-layout")
    lines.append("make migrate-layout DRY_RUN=1")
    lines.append("make intake-zip INTAKE_ARGS=\"--source apple --zip-path path/to/export.zip --participant P000001 --stage --dry-run\"")
    lines.append("make provenance DRY_RUN=1")
    lines.append("```")
    lines.append("")
    lines.append(f"Generated from git range: {since_tag}..{tag}")
    return "\n".join(lines)


def main(argv=None):
    p = argparse.ArgumentParser(description='Generate release notes markdown')
    p.add_argument('--version', required=True)
    p.add_argument('--tag', required=True)
    p.add_argument('--since-tag', default=None)
    # --outfile is optional; if not provided we write into docs/release_notes/
    p.add_argument('--outfile', default=None)
    p.add_argument('--participant', default='P000001')
    args = p.parse_args(argv)

    version = args.version
    tag = args.tag
    since_tag = args.since_tag
    if args.outfile:
        outfile = Path(args.outfile)
    else:
        outfile = Path('docs') / 'release_notes' / f'release_notes_{tag}.md'
    participant = args.participant

    # Ensure outfile dir exists
    outfile.parent.mkdir(parents=True, exist_ok=True)

    # Read highlights
    highlights = read_highlights()

    # Determine since-tag if not provided: prefer `git describe --tags --abbrev=0 <tag>^` when tag exists
    if not since_tag:
        # If the given tag exists locally, try to get its previous tag via <tag>^
        r_tag_exists = run(['git', 'rev-parse', '--verify', '--quiet', f'refs/tags/{tag}'])
        if r_tag_exists.returncode == 0:
            r = run(['git', 'describe', '--tags', '--abbrev=0', f'{tag}^'])
            if r.returncode == 0 and r.stdout.strip():
                since_tag = r.stdout.strip()
        if not since_tag:
            # fallback: try to find the most recent tag before the given tag by listing tags sorted by date
            r2 = run(['git', 'tag', '--sort=-creatordate'])
            tags = [l for l in r2.stdout.splitlines() if l.strip()]
            # find the index of tag and pick the next one; otherwise pick second-most recent
            if tag in tags:
                idx = tags.index(tag)
                since_tag = tags[idx+1] if idx+1 < len(tags) else ''
            else:
                since_tag = tags[1] if len(tags) > 1 else ''
    if not since_tag:
        since_tag = ''

    commits = parse_git_log(since_tag if since_tag else 'HEAD~200', tag)
    grouped = group_commits(commits)
    artifacts = find_artifacts(participant)
    md = compose_md(version, tag, highlights, grouped, artifacts, since_tag, participant)

    # Append a small badge suggestion to help downstream changelog updates
    badge_line = '\n\nðŸ“¦ Changelog updated: CHANGELOG.md at the end of the file.'
    md = md + badge_line
    outfile.write_text(md, encoding='utf-8')
    print(f"Wrote release notes to {outfile.as_posix()}")
    return 0


if __name__ == '__main__':
    sys.exit(main())
