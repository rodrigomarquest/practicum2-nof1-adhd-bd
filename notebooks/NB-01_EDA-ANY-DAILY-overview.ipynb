{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e4fdc6",
   "metadata": {},
   "source": [
    "# NB-01_EDA-ANY-DAILY-overview\n",
    "\n",
    "Purpose: Run EDA on the public daily subset only (`features_daily_public.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4aabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path; OUT=Path('notebooks')/ 'outputs'; (OUT/'figures').mkdir(parents=True,exist_ok=True); (OUT/'tables').mkdir(parents=True,exist_ok=True); (OUT/'manifests').mkdir(parents=True,exist_ok=True); print('out',OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74878721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob; c=glob('data/ai/*/snapshots/*/public_subset/features_daily_public.csv'); print('candidates',c); assert c, 'no public subset'; INPUT=Path(c[0]); print('INPUT',INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16717f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; df=pd.read_csv(INPUT); print('loaded',df.shape); assert 'date_utc' in df.columns; assert ('hr_mean' in df.columns) or ('sleep_total_minutes' in df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b239932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; import matplotlib.pyplot as plt; import seaborn as sns; sns.set(); (df.select_dtypes(include=[np.number]).describe().transpose()).to_csv('notebooks/outputs/tables/summary_stats.csv'); df.head(20).to_csv('notebooks/outputs/tables/head.csv',index=False); import hashlib; print('wrote tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,platform,hashlib; manifest={'env':'LOCAL','python':platform.python_version(),'input':{'path':str(INPUT),'sha256':hashlib.sha256(INPUT.read_bytes()).hexdigest()}}; (Path('notebooks')/'outputs'/'manifests'/'run_manifest.json').write_text(json.dumps(manifest,indent=2,sort_keys=True)); print('manifest written')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12577a1",
   "metadata": {},
   "source": [
    "# NB-01_EDA-ANY-DAILY-overview\n",
    "\n",
    "Purpose: Run EDA on the public daily subset only (`features_daily_public.csv`).\n",
    "- Environment detection: LOCAL / KAGGLE / COLAB\n",
    "- Hard block: notebook must not read `data/raw/**` or `data/etl/**` (AI-only guard)\n",
    "- Save non-sensitive figures/tables to `notebooks/outputs/{figures,tables,manifests}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cc857",
   "metadata": {},
   "source": [
    "# NB-01_EDA-ANY-DAILY-overview\n",
    "\n",
    "Purpose: Run EDA on the public daily subset only (`features_daily_public.csv`).\n",
    "- Environment detection: LOCAL / KAGGLE / COLAB\n",
    "- Hard block: notebook must not read `data/raw/**` or `data/etl/**` (AI-only guard)\n",
    "- Save non-sensitive figures/tables to `notebooks/outputs/{figures,tables,manifests}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cee4e78",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "1. Run all cells top-to-bottom. The notebook bootstraps minimal dependencies if missing (idempotent).\n",
    "2. It will locate the public subset CSV under `data/ai/**/public_subset/features_daily_public.csv`.\n",
    "3. The notebook enforces a schema guard: `date_utc` AND at least one of (`hr_mean`, `sleep_total_minutes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and output dirs\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "import platform\n",
    "\n",
    "OUT_BASE = Path('notebooks') / 'outputs'\n",
    "FIG_DIR = OUT_BASE / 'figures'\n",
    "TAB_DIR = OUT_BASE / 'tables'\n",
    "MAN_DIR = OUT_BASE / 'manifests'\n",
    "for d in (FIG_DIR, TAB_DIR, MAN_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "print('Outputs ->', OUT_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7dbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment detection: LOCAL / KAGGLE / COLAB\n",
    "def detect_env():\n",
    "    import os\n",
    "    if 'KAGGLE_URL_BASE' in os.environ:\n",
    "        return 'KAGGLE'\n",
    "    # Colab heuristics\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "        return 'COLAB'\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 'LOCAL'\n",
    "\n",
    "ENV = detect_env()\n",
    "print('Environment:', ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c772f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap minimal deps idempotently: pandas, matplotlib, seaborn, numpy\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "REQS = ['pandas', 'numpy', 'matplotlib', 'seaborn']\n",
    "missing = []\n",
    "for r in REQS:\n",
    "    if importlib.util.find_spec(r) is None:\n",
    "        missing.append(r)\n",
    "if missing:\n",
    "    print('Installing missing packages:', missing)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])\n",
    "else:\n",
    "    print('All required packages present')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ad539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate public CSV (search under data/ai/*/snapshots/*/public_subset)\n",
    "from glob import glob\n",
    "candidates = glob('data/ai/*/snapshots/*/public_subset/features_daily_public.csv')\n",
    "if not candidates:\n",
    "    raise FileNotFoundError('No public subset found under data/ai/*/snapshots/*/public_subset')\n",
    "INPUT_CSV = Path(candidates[0])\n",
    "print('Using public CSV:', INPUT_CSV)\n",
    "\n",
    "# Hard AI-only guard: if project contains data/raw or data/etl directories, block any attempt to read them\n",
    "if Path('data/raw').exists() or Path('data/etl').exists():\n",
    "    # We still allow the public_subset read, but ensure no code will reference raw/etl paths in produced artifacts\n",
    "    print('WARNING: data/raw or data/etl exists in repository root. The notebook will not read them.', file=sys.stderr)\n",
    "\n",
    "# Compute input SHA256\n",
    "def sha256_file(p: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    b = p.read_bytes()\n",
    "    h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "INPUT_SHA256 = sha256_file(INPUT_CSV)\n",
    "print('Input SHA256:', INPUT_SHA256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ed238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe and schema guard\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print('rows, cols =', df.shape)\n",
    "\n",
    "# Ensure date_utc present\n",
    "if 'date_utc' not in df.columns:\n",
    "    raise ValueError('Schema guard failed: date_utc column is required in features_daily_public.csv')\n",
    "\n",
    "# At least one of hr_mean OR sleep_total_minutes must be present\n",
    "if not (('hr_mean' in df.columns) or ('sleep_total_minutes' in df.columns)):\n",
    "    raise ValueError('Schema guard failed: one of hr_mean or sleep_total_minutes must be present')\n",
    "\n",
    "# Parse date_utc to datetime where possible\n",
    "try:\n",
    "    df['date_utc'] = pd.to_datetime(df['date_utc'])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Tolerate optional columns' absence; record available cols\n",
    "available_cols = list(df.columns)\n",
    "print('Available columns:', available_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967774ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: summary stats, missingness, correlations, and simple plots\n",
    "numeric = df.select_dtypes(include=[np.number])\n",
    "summary = numeric.describe().transpose()\n",
    "summary.to_csv(TAB_DIR / 'summary_stats.csv', index=True)\n",
    "print('Wrote summary stats ->', TAB_DIR / 'summary_stats.csv')\n",
    "\n",
    "# Head (non-sensitive)\n",
    "df.head(20).to_csv(TAB_DIR / 'head.csv', index=False)\n",
    "print('Wrote head ->', TAB_DIR / 'head.csv')\n",
    "\n",
    "# Missingness (percent)\n",
    "miss = pd.DataFrame({'missing_pct': df.isna().mean() * 100})\n",
    "miss.to_csv(TAB_DIR / 'missingness_pct.csv')\n",
    "print('Wrote missingness ->', TAB_DIR / 'missingness_pct.csv')\n",
    "\n",
    "# Correlations if enough numeric columns\n",
    "if numeric.shape[1] >= 2:\n",
    "    corr = numeric.corr(method='pearson')\n",
    "    corr.to_csv(TAB_DIR / 'correlations.csv')\n",
    "    print('Wrote correlations ->', TAB_DIR / 'correlations.csv')\n",
    "    # save a heatmap\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='vlag')\n",
    "    plt.title('Numeric Correlations')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / 'correlations_heatmap.png', dpi=150)\n",
    "    plt.close()\n",
    "    print('Wrote heatmap ->', FIG_DIR / 'correlations_heatmap.png')\n",
    "else:\n",
    "    print('Not enough numeric columns for correlations')\n",
    "\n",
    "# Histograms for hr_mean and sleep_total_minutes if present\n",
    "if 'hr_mean' in df.columns:\n",
    "    plt.figure()\n",
    "    sns.histplot(df['hr_mean'].dropna(), kde=False, bins=30)\n",
    "    plt.title('hr_mean distribution')\n",
    "    plt.savefig(FIG_DIR / 'hr_mean_hist.png', dpi=150)\n",
    "    plt.close()\n",
    "    print('Wrote hr_mean_hist ->', FIG_DIR / 'hr_mean_hist.png')\n",
    "\n",
    "if 'sleep_total_minutes' in df.columns:\n",
    "    plt.figure()\n",
    "    sns.histplot(df['sleep_total_minutes'].dropna(), kde=False, bins=30)\n",
    "    plt.title('sleep_total_minutes distribution')\n",
    "    plt.savefig(FIG_DIR / 'sleep_total_minutes_hist.png', dpi=150)\n",
    "    plt.close()\n",
    "    print('Wrote sleep_total_minutes_hist ->', FIG_DIR / 'sleep_total_minutes_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write run manifest with env, params, input hash, and produced artifact checksums\n",
    "import pkgutil\n",
    "import pkg_resources\n",
    "\n",
    "def lib_version(name: str) -> str:\n",
    "    try:\n",
    "        return pkg_resources.get_distribution(name).version\n",
    "    except Exception:\n",
    "        try:\n",
    "            import importlib\n",
    "            m = importlib.import_module(name)\n",
    "            return getattr(m, '__version__', 'unknown')\n",
    "        except Exception:\n",
    "            return 'unknown'\n",
    "\n",
    "manifest = {\n",
    "    'env': ENV,\n",
    "    'python': platform.python_version(),\n",
    "    'libs': {\n",
    "        'pandas': lib_version('pandas'),\n",
    "        'numpy': lib_version('numpy'),\n",
    "        'matplotlib': lib_version('matplotlib'),\n",
    "        'seaborn': lib_version('seaborn'),\n",
    "    },\n",
    "    'input': {\n",
    "        'path': str(INPUT_CSV),\n",
    "        'sha256': INPUT_SHA256,\n",
    "    },\n",
    "    'params': {\n",
    "        'found_columns': available_cols\n",
    "    },\n",
    "    'artifacts': []\n",
    "}\n",
    "\n",
    "for p in sorted((TAB_DIR).glob('*')) + sorted((FIG_DIR).glob('*')):\n",
    "    if p.is_file():\n",
    "        s = hashlib.sha256(p.read_bytes()).hexdigest()\n",
    "        manifest['artifacts'].append({'path': str(p), 'sha256': s})\n",
    "\n",
    "manifest_path = MAN_DIR / 'run_manifest.json'\n",
    "with manifest_path.open('w', encoding='utf-8') as f:\n",
    "    json.dump(manifest, f, indent=2, sort_keys=True)\n",
    "print('Wrote run manifest ->', manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a941a0b",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- All produced artifacts are under `notebooks/outputs/**`.\n",
    "- The notebook intentionally searches only for `public_subset/features_daily_public.csv` and does not reference `data/raw` or `data/etl`.\n",
    "- If you need to run on a different participant/snapshot, place the public subset under `data/ai/<PID>/snapshots/<SNAP>/public_subset/` and rerun."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
