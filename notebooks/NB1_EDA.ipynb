{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b938fc",
   "metadata": {},
   "source": [
    "# NB1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Purpose**: Comprehensive exploratory data analysis for P000001, covering multimodal digital phenotyping data.\n",
    "\n",
    "**Pipeline**: practicum2-nof1-adhd-bd **v4.1.7** (Nov 20, 2025)  \n",
    "**Participant**: P000001  \n",
    "**Snapshot**: 2025-11-07  \n",
    "**Default Filter**: Gold period only (>= 2021-05-11, Amazfit era with reliable HR/HRV)\n",
    "\n",
    "This notebook provides:\n",
    "1. Summary statistics across all domains (sleep, HR, activity, screen time)\n",
    "2. **Data quality filter** (gold vs legacy period comparison)\n",
    "3. Temporal visualizations (time series, trends, seasonality)\n",
    "4. Distribution analyses (histograms, KDE, box plots)\n",
    "5. Segment-level insights\n",
    "6. PBSI label distribution and evolution (v4.1.7: intuitive sign convention)\n",
    "7. Publication-quality figures\n",
    "\n",
    "**v4.1.7 Updates**:\n",
    "- Added `GOLD_ONLY` flag to filter legacy period (2017-2020, iPhone-only, no HR/HRV)\n",
    "- Default: `True` (gold period >= 2021-05-11 only)\n",
    "- New section comparing data coverage between periods\n",
    "- Aligns with Stage 5 temporal filter in modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "PARTICIPANT = \"P000001\"\n",
    "SNAPSHOT = \"2025-11-07\"\n",
    "REPO_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY FILTER (v4.1.7)\n",
    "# ============================================================================\n",
    "# Gold period: >= 2021-05-11 (Amazfit GTR 2 era with reliable HR/HRV)\n",
    "# Legacy period: 2017-2020 (iPhone-only, no cardio sensors, MNAR)\n",
    "#\n",
    "# Recommendation: Use GOLD_ONLY=True for analysis to avoid bias from missing HR/HRV\n",
    "# Set to False only for temporal coverage analysis or comparing periods\n",
    "# ============================================================================\n",
    "GOLD_ONLY = True  # Default: Filter to gold period (>= 2021-05-11)\n",
    "GOLD_CUTOFF = \"2021-05-11\"  # Amazfit GTR 2 acquisition date\n",
    "\n",
    "# Paths\n",
    "ETL_BASE = REPO_ROOT / \"data\" / \"etl\" / PARTICIPANT / SNAPSHOT\n",
    "JOINED_DIR = ETL_BASE / \"joined\"\n",
    "QC_DIR = ETL_BASE / \"qc\"\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"ETL base: {ETL_BASE}\")\n",
    "print(f\"Snapshot: {PARTICIPANT} / {SNAPSHOT}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DATA FILTER: {'Gold period only (>= 2021-05-11)' if GOLD_ONLY else 'All periods (2017-2025)'}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593925d",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7766a44",
   "metadata": {},
   "source": [
    "## Data Quality Context (v4.1.7)\n",
    "\n",
    "**Two Data Periods**:\n",
    "\n",
    "1. **Legacy Period (2017-2020)**: \n",
    "   - iPhone-only tracking (iOS Health app)\n",
    "   - **No cardiovascular sensors** (HR/HRV unavailable - systematic missingness)\n",
    "   - Screen time, steps, sleep duration available\n",
    "   - Missing data: MNAR (Missing Not At Random)\n",
    "   - Not suitable for PBSI or cardio analysis\n",
    "\n",
    "2. **Gold Period (2021-05-11 onwards)**: \n",
    "   - Amazfit GTR 2 smartwatch added\n",
    "   - **Complete multimodal data** (HR, HRV, steps, sleep, screen time)\n",
    "   - Missing data: MAR (Missing At Random) - sporadic, suitable for imputation\n",
    "   - Recommended for all analysis requiring cardio features\n",
    "\n",
    "**Current Filter**: `GOLD_ONLY = {GOLD_ONLY}` \n",
    "- Change in cell 2 to include/exclude legacy period\n",
    "- Default: `True` (gold period only) for unbiased analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4479e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unified dataset\n",
    "unified_path = JOINED_DIR / \"features_daily_unified.csv\"\n",
    "labeled_path = JOINED_DIR / \"features_daily_labeled.csv\"\n",
    "\n",
    "if not unified_path.exists():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\u274c PIPELINE DATA NOT FOUND\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nRequired file missing: {unified_path}\")\n",
    "    print(\"\\n\ud83d\udccb To generate the required data, run the ETL pipeline:\")\n",
    "    print(f\"\\n   make aggregate PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    print(f\"   make unify PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    print(f\"   make label PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    print(f\"   make segment PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    print(\"\\n\u26a1 Or run all stages at once:\")\n",
    "    print(f\"   make pipeline PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    print(\"\\n\ud83d\udca1 Check NB0_DataRead.ipynb to see which stages are complete\")\n",
    "    print(\"=\" * 80)\n",
    "    raise FileNotFoundError(f\"Pipeline data not ready. See instructions above.\")\n",
    "\n",
    "df_unified = pd.read_csv(unified_path)\n",
    "df_unified['date'] = pd.to_datetime(df_unified['date'])\n",
    "\n",
    "print(f\"\u2713 Loaded features_daily_unified.csv: {df_unified.shape}\")\n",
    "\n",
    "# Load labeled dataset if available\n",
    "if labeled_path.exists():\n",
    "    df_labeled = pd.read_csv(labeled_path)\n",
    "    df_labeled['date'] = pd.to_datetime(df_labeled['date'])\n",
    "    print(f\"\u2713 Loaded features_daily_labeled.csv: {df_labeled.shape}\")\n",
    "    df = df_labeled  # Use labeled as primary\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Labeled dataset not available, using unified only\")\n",
    "    print(f\"    Run: make label PID={PARTICIPANT} SNAPSHOT={SNAPSHOT}\")\n",
    "    df = df_unified\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Apply gold period filter if enabled\n",
    "if GOLD_ONLY:\n",
    "    df_original = df.copy()\n",
    "    df = df[df['date'] >= GOLD_CUTOFF].reset_index(drop=True)\n",
    "    print(f\"\\n\ud83c\udfaf GOLD PERIOD FILTER APPLIED:\")\n",
    "    print(f\"   Original: {len(df_original):,} days ({df_original['date'].min()} to {df_original['date'].max()})\")\n",
    "    print(f\"   Filtered: {len(df):,} days ({df['date'].min()} to {df['date'].max()})\")\n",
    "    print(f\"   Excluded: {len(df_original) - len(df):,} days (2017-2020, iPhone-only, no HR/HRV)\")\n",
    "    print(f\"   Rationale: Avoid bias from MNAR (Missing Not At Random) cardio data\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f  Using ALL periods (including 2017-2020 with missing HR/HRV)\")\n",
    "\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Total days: {len(df):,}\")\n",
    "print(f\"Time span: {(df['date'].max() - df['date'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c163fb3",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature groups\n",
    "feature_groups = {\n",
    "    \"Sleep\": ['sleep_total_h', 'sleep_efficiency'],\n",
    "    \"Cardiovascular\": ['hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hrv_rmssd'],\n",
    "    \"Activity\": ['steps', 'exercise_min', 'move_kcal'],\n",
    "    \"Screen Time\": ['screen_min', 'notifications'],\n",
    "    \"Labels\": ['segment_id', 'pbsi_score', 'label_3cls'] if 'pbsi_score' in df.columns else []\n",
    "}\n",
    "\n",
    "# Print available features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVAILABLE FEATURES BY DOMAIN\")\n",
    "print(\"=\"*80)\n",
    "for domain, features in feature_groups.items():\n",
    "    available = [f for f in features if f in df.columns]\n",
    "    missing = [f for f in features if f not in df.columns]\n",
    "    if available:\n",
    "        print(f\"\\n{domain}:\")\n",
    "        print(f\"  \u2713 Available: {', '.join(available)}\")\n",
    "    if missing:\n",
    "        print(f\"  \u26a0\ufe0f  Missing: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_cols = [c for c in ['sleep_total_h', 'hr_mean', 'hrv_rmssd', 'steps', 'screen_min'] if c in df.columns]\n",
    "if summary_cols:\n",
    "    summary = df[summary_cols].describe()\n",
    "    print(summary.round(2))\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No numeric features available for summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c5207",
   "metadata": {},
   "source": [
    "## 3. Missingness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85b7fb",
   "metadata": {},
   "source": [
    "### Data Coverage by Period (Gold vs Legacy)\n",
    "\n",
    "Compare data availability between legacy (2017-2020, iPhone-only) and gold (2021+, Amazfit) periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263af627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset (both periods) for comparison\n",
    "if GOLD_ONLY:\n",
    "    df_full = pd.read_csv(labeled_path if labeled_path.exists() else unified_path)\n",
    "    df_full['date'] = pd.to_datetime(df_full['date'])\n",
    "    df_full = df_full.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Split into periods\n",
    "    df_legacy = df_full[df_full['date'] < GOLD_CUTOFF]\n",
    "    df_gold = df_full[df_full['date'] >= GOLD_CUTOFF]\n",
    "    \n",
    "    # Compare cardio coverage\n",
    "    cardio_features = ['hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hrv_rmssd']\n",
    "    cardio_features = [f for f in cardio_features if f in df_full.columns]\n",
    "    \n",
    "    if cardio_features:\n",
    "        coverage_legacy = 100 - (df_legacy[cardio_features].isnull().sum() / len(df_legacy) * 100)\n",
    "        coverage_gold = 100 - (df_gold[cardio_features].isnull().sum() / len(df_gold) * 100)\n",
    "        \n",
    "        # Create comparison table\n",
    "        comparison = pd.DataFrame({\n",
    "            'Legacy (2017-2020)': coverage_legacy,\n",
    "            'Gold (2021+)': coverage_gold,\n",
    "            '\u0394 (improvement)': coverage_gold - coverage_legacy\n",
    "        })\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CARDIOVASCULAR DATA COVERAGE COMPARISON (%)\")\n",
    "        print(\"=\"*80)\n",
    "        print(comparison.round(1).to_string())\n",
    "        print(f\"\\nLegacy period: {len(df_legacy):,} days\")\n",
    "        print(f\"Gold period:   {len(df_gold):,} days\")\n",
    "        \n",
    "        # Visualization\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        comparison[['Legacy (2017-2020)', 'Gold (2021+)']].plot(kind='bar', ax=ax, color=['#e74c3c', '#27ae60'])\n",
    "        ax.set_ylabel('Data Coverage (%)')\n",
    "        ax.set_xlabel('Feature')\n",
    "        ax.set_title('Cardiovascular Data Coverage: Legacy vs Gold Period', fontsize=14, weight='bold')\n",
    "        ax.axhline(80, color='orange', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_ylim([0, 105])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n\ud83d\udca1 Insight: Gold period has {coverage_gold.mean():.1f}% avg coverage vs {coverage_legacy.mean():.1f}% in legacy\")\n",
    "        print(f\"   Recommendation: Use GOLD_ONLY=True (currently: {GOLD_ONLY})\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  No cardiovascular features available for comparison\")\n",
    "else:\n",
    "    print(f\"\u2139\ufe0f  Period comparison skipped (GOLD_ONLY={GOLD_ONLY})\")\n",
    "    print(f\"   Set GOLD_ONLY=True and re-run to see legacy vs gold comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ffd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missingness\n",
    "key_features = [c for c in [\n",
    "    'sleep_total_h', 'sleep_efficiency',\n",
    "    'hr_mean', 'hrv_rmssd',\n",
    "    'steps', 'exercise_min',\n",
    "    'screen_min', 'notifications'\n",
    "] if c in df.columns]\n",
    "\n",
    "missingness = df[key_features].isnull().sum() / len(df) * 100\n",
    "missingness = missingness.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSINGNESS BY FEATURE (%)\")\n",
    "print(\"=\"*80)\n",
    "for feature, pct in missingness.items():\n",
    "    status = \"\u2713\" if pct < 5 else \"\u26a0\ufe0f\" if pct < 20 else \"\u274c\"\n",
    "    print(f\"{status} {feature:25s}: {pct:6.2f}%\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "missingness.plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Missingness (%)')\n",
    "ax.set_title('Data Completeness by Feature', fontsize=14, weight='bold')\n",
    "ax.axvline(5, color='green', linestyle='--', alpha=0.5, label='5% threshold')\n",
    "ax.axvline(20, color='orange', linestyle='--', alpha=0.5, label='20% threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef8294",
   "metadata": {},
   "source": [
    "## 4. Temporal Trends\n",
    "\n",
    "### 4.1 Full Timeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-panel time series plot\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "# Sleep duration\n",
    "if 'sleep_total_h' in df.columns:\n",
    "    axes[0].plot(df['date'], df['sleep_total_h'], alpha=0.6, linewidth=0.8, color='navy')\n",
    "    axes[0].set_ylabel('Sleep (hours)', fontsize=11, weight='bold')\n",
    "    axes[0].set_title('8-Year Multimodal Digital Phenotyping Timeline', fontsize=14, weight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].axhline(7, color='green', linestyle='--', alpha=0.4, label='7h target')\n",
    "    axes[0].legend()\n",
    "\n",
    "# Heart rate\n",
    "if 'hr_mean' in df.columns:\n",
    "    axes[1].plot(df['date'], df['hr_mean'], alpha=0.6, linewidth=0.8, color='crimson')\n",
    "    axes[1].set_ylabel('HR Mean (bpm)', fontsize=11, weight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].axhline(df['hr_mean'].mean(), color='red', linestyle='--', alpha=0.4, label='Mean')\n",
    "    axes[1].legend()\n",
    "\n",
    "# Steps\n",
    "if 'steps' in df.columns:\n",
    "    axes[2].plot(df['date'], df['steps'], alpha=0.6, linewidth=0.8, color='forestgreen')\n",
    "    axes[2].set_ylabel('Steps', fontsize=11, weight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].axhline(10000, color='green', linestyle='--', alpha=0.4, label='10k target')\n",
    "    axes[2].legend()\n",
    "\n",
    "# Screen time\n",
    "if 'screen_min' in df.columns:\n",
    "    axes[3].plot(df['date'], df['screen_min'] / 60, alpha=0.6, linewidth=0.8, color='darkorange')\n",
    "    axes[3].set_ylabel('Screen Time (hours)', fontsize=11, weight='bold')\n",
    "    axes[3].set_xlabel('Date', fontsize=11, weight='bold')\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Full timeline visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7dd93",
   "metadata": {},
   "source": [
    "### 4.2 Yearly Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41517935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Yearly aggregates\n",
    "yearly_cols = [c for c in ['sleep_total_h', 'hr_mean', 'steps', 'screen_min'] if c in df.columns]\n",
    "if yearly_cols:\n",
    "    yearly_stats = df.groupby('year')[yearly_cols].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"YEARLY SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(yearly_stats.round(2))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(yearly_cols[:4]):\n",
    "        yearly_mean = df.groupby('year')[col].mean()\n",
    "        yearly_std = df.groupby('year')[col].std()\n",
    "        \n",
    "        axes[idx].bar(yearly_mean.index, yearly_mean.values, yerr=yearly_std.values, \n",
    "                      alpha=0.7, capsize=5, color='steelblue')\n",
    "        axes[idx].set_xlabel('Year', fontweight='bold')\n",
    "        axes[idx].set_ylabel(col, fontweight='bold')\n",
    "        axes[idx].set_title(f'{col} - Yearly Mean \u00b1 Std', fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bb346",
   "metadata": {},
   "source": [
    "## 5. Distribution Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c694c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms with KDE\n",
    "dist_cols = [c for c in ['sleep_total_h', 'hr_mean', 'hrv_rmssd', 'steps'] if c in df.columns]\n",
    "\n",
    "if dist_cols:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(dist_cols[:4]):\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        axes[idx].hist(data, bins=50, alpha=0.6, color='steelblue', edgecolor='black', density=True)\n",
    "        \n",
    "        # Add KDE\n",
    "        try:\n",
    "            from scipy import stats\n",
    "            density = stats.gaussian_kde(data)\n",
    "            xs = np.linspace(data.min(), data.max(), 200)\n",
    "            axes[idx].plot(xs, density(xs), 'r-', linewidth=2, label='KDE')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        axes[idx].axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.1f}')\n",
    "        axes[idx].axvline(data.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {data.median():.1f}')\n",
    "        \n",
    "        axes[idx].set_xlabel(col, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Density', fontweight='bold')\n",
    "        axes[idx].set_title(f'Distribution: {col}', fontweight='bold')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\u2713 Distribution analyses complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c2dec",
   "metadata": {},
   "source": [
    "## 6. PBSI Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label_3cls' in df.columns and 'pbsi_score' in df.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PBSI LABEL DISTRIBUTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    label_counts = df['label_3cls'].value_counts().sort_index()\n",
    "    label_pct = df['label_3cls'].value_counts(normalize=True).sort_index() * 100\n",
    "    \n",
    "    # v4.1.7: Intuitive sign convention (higher PBSI = better regulation)\n",
    "    label_names = {\n",
    "        1: 'Regulated/High PBSI (+1)', \n",
    "        0: 'Typical/Mid PBSI (0)', \n",
    "        -1: 'Dysregulated/Low PBSI (-1)'\n",
    "    }\n",
    "    \n",
    "    for label in [1, 0, -1]:\n",
    "        if label in label_counts.index:\n",
    "            print(f\"{label_names[label]:30s}: {label_counts[label]:4d} days ({label_pct[label]:5.1f}%)\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = ['green', 'yellow', 'red']\n",
    "    axes[0].pie(label_counts.values, labels=[label_names[l] for l in label_counts.index], \n",
    "                autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    axes[0].set_title('PBSI Label Distribution (v4.1.7)', fontweight='bold')\n",
    "    \n",
    "    # PBSI score distribution\n",
    "    pbsi_data = df['pbsi_score'].dropna()\n",
    "    axes[1].hist(pbsi_data, bins=50, alpha=0.6, color='steelblue', edgecolor='black')\n",
    "    axes[1].axvline(-0.370, color='red', linestyle='--', linewidth=2, label='P25 (dysregulated)')\n",
    "    axes[1].axvline(+0.321, color='green', linestyle='--', linewidth=2, label='P75 (regulated)')\n",
    "    axes[1].set_xlabel('PBSI Score', fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontweight='bold')\n",
    "    axes[1].set_title('PBSI Score Distribution (v4.1.7: Higher = Better)', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Time series of labels\n",
    "    axes[2].scatter(df['date'], df['label_3cls'], alpha=0.3, s=10)\n",
    "    axes[2].set_xlabel('Date', fontweight='bold')\n",
    "    axes[2].set_ylabel('Label', fontweight='bold')\n",
    "    axes[2].set_yticks([1, 0, -1])\n",
    "    axes[2].set_yticklabels(['Regulated', 'Typical', 'Dysregulated'])\n",
    "    axes[2].set_title('Label Evolution Over Time', fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 PBSI analysis complete (v4.1.7: intuitive sign convention)\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  PBSI labels not available (run Stage 3: Label)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1dd98",
   "metadata": {},
   "source": [
    "## 7. Segment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e27bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segment_id' in df.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEHAVIOURAL SEGMENT ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    n_segments = df['segment_id'].nunique()\n",
    "    segment_sizes = df.groupby('segment_id').size()\n",
    "    \n",
    "    print(f\"Total segments: {n_segments}\")\n",
    "    print(f\"Segment size (days):\")\n",
    "    print(f\"  Mean: {segment_sizes.mean():.1f}\")\n",
    "    print(f\"  Median: {segment_sizes.median():.0f}\")\n",
    "    print(f\"  Range: {segment_sizes.min()}-{segment_sizes.max()}\")\n",
    "    \n",
    "    # Segment size distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].hist(segment_sizes, bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[0].set_xlabel('Segment Size (days)', fontweight='bold')\n",
    "    axes[0].set_ylabel('Frequency', fontweight='bold')\n",
    "    axes[0].set_title('Distribution of Segment Sizes', fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Segments over time\n",
    "    segment_starts = df.groupby('segment_id')['date'].min()\n",
    "    axes[1].plot(segment_starts.values, segment_starts.index, marker='o', markersize=3, alpha=0.6)\n",
    "    axes[1].set_xlabel('Date', fontweight='bold')\n",
    "    axes[1].set_ylabel('Segment ID', fontweight='bold')\n",
    "    axes[1].set_title('Segment Timeline', fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 Segment analysis complete\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Segment IDs not available (run Stage 3: Label with segments)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec7284",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = [c for c in [\n",
    "    'sleep_total_h', 'sleep_efficiency',\n",
    "    'hr_mean', 'hrv_rmssd',\n",
    "    'steps', 'exercise_min',\n",
    "    'screen_min'\n",
    "] if c in df.columns]\n",
    "\n",
    "if len(corr_cols) >= 3:\n",
    "    corr_matrix = df[corr_cols].corr()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, ax=ax, \n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 Correlation analysis complete\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Insufficient features for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57604df",
   "metadata": {},
   "source": [
    "## 9. Behavioural Insights\n",
    "\n",
    "### Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94737a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEHAVIOURAL INSIGHTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Sleep patterns\n",
    "if 'sleep_total_h' in df.columns:\n",
    "    sleep_mean_by_year = df.groupby('year')['sleep_total_h'].mean()\n",
    "    sleep_trend = sleep_mean_by_year.iloc[-1] - sleep_mean_by_year.iloc[0]\n",
    "    insights.append(f\"Sleep: {sleep_trend:+.1f}h change from {df['year'].min()} to {df['year'].max()}\")\n",
    "    \n",
    "    low_sleep_days = (df['sleep_total_h'] < 5).sum()\n",
    "    if low_sleep_days > 0:\n",
    "        insights.append(f\"Sleep: {low_sleep_days} days with <5 hours ({low_sleep_days/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Heart rate\n",
    "if 'hr_mean' in df.columns:\n",
    "    hr_mean_by_year = df.groupby('year')['hr_mean'].mean()\n",
    "    hr_trend = hr_mean_by_year.iloc[-1] - hr_mean_by_year.iloc[0]\n",
    "    insights.append(f\"HR: {hr_trend:+.1f} bpm change over study period\")\n",
    "\n",
    "# Activity\n",
    "if 'steps' in df.columns:\n",
    "    steps_mean_by_year = df.groupby('year')['steps'].mean()\n",
    "    steps_trend = steps_mean_by_year.iloc[-1] - steps_mean_by_year.iloc[0]\n",
    "    insights.append(f\"Steps: {steps_trend:+.0f} steps/day change over study period\")\n",
    "    \n",
    "    low_activity_days = (df['steps'] < 3000).sum()\n",
    "    if low_activity_days > 0:\n",
    "        insights.append(f\"Activity: {low_activity_days} days with <3000 steps ({low_activity_days/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Screen time\n",
    "if 'screen_min' in df.columns:\n",
    "    screen_mean = df['screen_min'].mean() / 60\n",
    "    insights.append(f\"Screen: Average {screen_mean:.1f} hours/day\")\n",
    "\n",
    "# PBSI\n",
    "if 'label_3cls' in df.columns:\n",
    "    stable_pct = (df['label_3cls'] == 1).sum() / len(df) * 100\n",
    "    unstable_pct = (df['label_3cls'] == -1).sum() / len(df) * 100\n",
    "    insights.append(f\"PBSI: {stable_pct:.1f}% stable days, {unstable_pct:.1f}% unstable days\")\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"  {i}. {insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29784a",
   "metadata": {},
   "source": [
    "## 10. Notable Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify extreme periods\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTABLE EPISODES (Extreme Values)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lowest sleep period (7-day moving average)\n",
    "if 'sleep_total_h' in df.columns:\n",
    "    df['sleep_ma7'] = df['sleep_total_h'].rolling(7, min_periods=1).mean()\n",
    "    lowest_sleep_idx = df['sleep_ma7'].idxmin()\n",
    "    lowest_sleep_date = df.loc[lowest_sleep_idx, 'date']\n",
    "    lowest_sleep_val = df.loc[lowest_sleep_idx, 'sleep_ma7']\n",
    "    print(f\"\\n\ud83d\udcc9 Lowest sleep period (7-day avg):\")\n",
    "    print(f\"   Date: {lowest_sleep_date.date()}, Value: {lowest_sleep_val:.2f}h/night\")\n",
    "\n",
    "# Highest activity period\n",
    "if 'steps' in df.columns:\n",
    "    df['steps_ma7'] = df['steps'].rolling(7, min_periods=1).mean()\n",
    "    highest_steps_idx = df['steps_ma7'].idxmax()\n",
    "    highest_steps_date = df.loc[highest_steps_idx, 'date']\n",
    "    highest_steps_val = df.loc[highest_steps_idx, 'steps_ma7']\n",
    "    print(f\"\\n\ud83d\udcc8 Highest activity period (7-day avg):\")\n",
    "    print(f\"   Date: {highest_steps_date.date()}, Value: {highest_steps_val:.0f} steps/day\")\n",
    "\n",
    "# Highest HR period\n",
    "if 'hr_mean' in df.columns:\n",
    "    df['hr_ma7'] = df['hr_mean'].rolling(7, min_periods=1).mean()\n",
    "    highest_hr_idx = df['hr_ma7'].idxmax()\n",
    "    highest_hr_date = df.loc[highest_hr_idx, 'date']\n",
    "    highest_hr_val = df.loc[highest_hr_idx, 'hr_ma7']\n",
    "    print(f\"\\n\u2764\ufe0f  Highest HR period (7-day avg):\")\n",
    "    print(f\"   Date: {highest_hr_date.date()}, Value: {highest_hr_val:.1f} bpm\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1131f825",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This EDA notebook provides a comprehensive overview of 8 years of multimodal digital phenotyping data for P000001.\n",
    "\n",
    "**Key Observations**:\n",
    "- Dataset spans {start_date} to {end_date} ({total_days:,} days)\n",
    "- Primary domains: Sleep, Cardiovascular, Activity, Screen Time\n",
    "- Behavioral segmentation: {n_segments} distinct periods\n",
    "- PBSI labels: {stable_pct:.1f}% stable, {neutral_pct:.1f}% neutral, {unstable_pct:.1f}% unstable\n",
    "\n",
    "**Publication-Quality Figures**:\n",
    "- All plots use consistent styling and clear labels\n",
    "- Recommended for paper: Timeline (Section 4.1), Distributions (Section 5), PBSI (Section 6)\n",
    "\n",
    "**Next Steps**:\n",
    "- Proceed to **NB2_Baseline.ipynb** (Stage 6: ML6 static classifier) for logistic regression analysis\n",
    "- Proceed to **NB3_DeepLearning.ipynb** (Stage 7: ML7 LSTM) for LSTM sequence modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}