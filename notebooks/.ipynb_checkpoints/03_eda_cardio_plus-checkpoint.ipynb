{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c899ad",
   "metadata": {},
   "source": [
    "# 03 · EDA — Cardiovascular (Enhanced)\n",
    "\n",
    "Interactive + weekly aggregation + consolidated Excel summary.\n",
    "\n",
    "**Inputs**: `features_cardiovascular.csv`, `features_daily_updated.csv`, `extract_manifest.json`, `cardio_manifest.json`\n",
    "**Outputs**: PNG/HTML figures in `eda_outputs/`, JSON + Excel summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc28c55-96d7-4baf-8c4f-e9a13c858dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotly renderer: notebook_connected\n"
     ]
    }
   ],
   "source": [
    "# Plotly renderer robusto para VSCode/Jupyter/Browser\n",
    "import os\n",
    "import plotly.io as pio; pio.renderers.default = \"browser\"; pio.renderers.default\n",
    "\n",
    "def _pick_renderer():\n",
    "    # VSCode\n",
    "    if os.environ.get(\"VSCODE_PID\"):\n",
    "        return \"vscode\"\n",
    "    # JupyterLab/Notebook recentes\n",
    "    for r in (\"notebook_connected\", \"jupyterlab\"):\n",
    "        if r in pio.renderers:\n",
    "            return r\n",
    "    # Fallback universal (salva <iframe>)\n",
    "    return \"browser\"\n",
    "\n",
    "pio.renderers.default = _pick_renderer()\n",
    "print(\"Plotly renderer:\", pio.renderers.default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cbf3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAPDIR = data_ai\\P000001\\snapshots\\2025-09-29\n"
     ]
    }
   ],
   "source": [
    "import os, json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from datetime import datetime\n",
    "\n",
    "PID = 'P000001'\n",
    "SNAP = '2025-09-29'  # <- altere aqui se quiser outro snapshot\n",
    "AGG = 'median'       # 'median' ou 'mean' para weekly aggregation\n",
    "\n",
    "SNAPDIR = Path('data_ai')/PID/'snapshots'/SNAP\n",
    "OUTDIR  = SNAPDIR/'eda_outputs'\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "print('SNAPDIR =', SNAPDIR)\n",
    "pio.renderers.default = 'notebook'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8d4d7",
   "metadata": {},
   "source": [
    "## 01 | Read manifests (reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59107b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_manifest keys: []\n",
      "cardio_manifest keys: []\n"
     ]
    }
   ],
   "source": [
    "extract_manifest = {}\n",
    "cardio_manifest = {}\n",
    "em = SNAPDIR/'extract_manifest.json'\n",
    "cm = SNAPDIR/'cardio_manifest.json'\n",
    "if em.exists(): extract_manifest = json.loads(em.read_text(encoding='utf-8'))\n",
    "if cm.exists(): cardio_manifest  = json.loads(cm.read_text(encoding='utf-8'))\n",
    "print('extract_manifest keys:', list(extract_manifest.keys()))\n",
    "print('cardio_manifest keys:', list(cardio_manifest.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd487e",
   "metadata": {},
   "source": [
    "## 02 | Load data & QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb58e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'features_cardiovascular', 'empty': True}\n",
      "{'name': 'features_daily_updated', 'empty': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _read_csv(path: Path, dtcols=('date',)):\n",
    "    if not path.exists(): return pd.DataFrame()\n",
    "    return pd.read_csv(path, parse_dates=[c for c in dtcols if c in pd.read_csv(path, nrows=0).columns])\n",
    "\n",
    "feat_cardio = _read_csv(SNAPDIR/'features_cardiovascular.csv', ('date',))\n",
    "feat_dailyu = _read_csv(SNAPDIR/'features_daily_updated.csv', ('date',))\n",
    "\n",
    "def qc_report(df: pd.DataFrame, name: str):\n",
    "    if df.empty:\n",
    "        return {'name': name, 'empty': True}\n",
    "    cols_num = [c for c in df.columns if c!='date' and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    rep = {\n",
    "        'name': name,\n",
    "        'empty': False,\n",
    "        'n_rows': int(len(df)),\n",
    "        'date_min': str(df['date'].min().date()) if 'date' in df else None,\n",
    "        'date_max': str(df['date'].max().date()) if 'date' in df else None,\n",
    "        'n_na_total': int(df.isna().sum().sum()),\n",
    "        'n_num_cols': len(cols_num)\n",
    "    }\n",
    "    return rep\n",
    "\n",
    "qc_cardio = qc_report(feat_cardio, 'features_cardiovascular')\n",
    "qc_dailyu = qc_report(feat_dailyu, 'features_daily_updated')\n",
    "print(qc_cardio); print(qc_dailyu)\n",
    "\n",
    "(SNAPDIR/'eda_outputs'/'eda_qc.json').write_text(json.dumps({'cardio': qc_cardio, 'dailyu': qc_dailyu}, indent=2), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa44773",
   "metadata": {},
   "source": [
    "## 03 | Temporal trends (HR / HRV) — static + interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13cdbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_cardiovascular.csv is empty — skipping temporal trends\n"
     ]
    }
   ],
   "source": [
    "if feat_cardio.empty:\n",
    "    print('features_cardiovascular.csv is empty — skipping temporal trends')\n",
    "else:\n",
    "    df = feat_cardio.copy().sort_values('date')\n",
    "    # heuristics to detect columns\n",
    "    hr_cols  = [c for c in df.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "    hrv_cols = [c for c in df.columns if re.search(r'hrv.*(sdnn|sdnn_ms).*mean', c)]\n",
    "    # ---- matplotlib (static)\n",
    "    if hr_cols:\n",
    "        plt.figure(figsize=(11,3))\n",
    "        plt.plot(df['date'], df[hr_cols[0]])\n",
    "        plt.title(f'Daily HR mean — {hr_cols[0]}'); plt.xlabel('date'); plt.ylabel('bpm'); plt.tight_layout()\n",
    "        plt.savefig(OUTDIR/'trend_hr_mean.png'); plt.show()\n",
    "    if hrv_cols:\n",
    "        plt.figure(figsize=(11,3))\n",
    "        plt.plot(df['date'], df[hrv_cols[0]])\n",
    "        plt.title(f'Daily HRV (SDNN) mean — {hrv_cols[0]}'); plt.xlabel('date'); plt.ylabel('ms'); plt.tight_layout()\n",
    "        plt.savefig(OUTDIR/'trend_hrv_sdnn_mean.png'); plt.show()\n",
    "    # ---- plotly (interactive)\n",
    "    if hr_cols:\n",
    "        fig = px.line(df, x='date', y=hr_cols[0], title=f'HR mean (interactive) — {hr_cols[0]}')\n",
    "        fig.write_html(str(OUTDIR/'trend_hr_mean.html'))\n",
    "        fig.show()\n",
    "    if hrv_cols:\n",
    "        fig = px.line(df, x='date', y=hrv_cols[0], title=f'HRV SDNN mean (interactive) — {hrv_cols[0]}')\n",
    "        fig.write_html(str(OUTDIR/'trend_hrv_sdnn_mean.html'))\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a48686",
   "metadata": {},
   "source": [
    "## 04 | Weekly aggregation (median/mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35018a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = pd.DataFrame()\n",
    "if not feat_cardio.empty:\n",
    "    df = feat_cardio.copy().set_index('date').sort_index()\n",
    "    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    aggfn = np.median if AGG=='median' else np.mean\n",
    "    weekly = df[num_cols].resample('W').apply(aggfn)\n",
    "    weekly.index.name = 'week'\n",
    "    weekly.to_csv(OUTDIR/'weekly_cardio.csv')\n",
    "    display(weekly.head())\n",
    "    # interactive pair: HR vs HRV weekly\n",
    "    hr_cols  = [c for c in weekly.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "    hrv_cols = [c for c in weekly.columns if re.search(r'hrv.*(sdnn|sdnn_ms).*mean', c)]\n",
    "    if hr_cols and hrv_cols:\n",
    "        wdf = weekly.reset_index()\n",
    "        fig = px.scatter(wdf, x=hr_cols[0], y=hrv_cols[0], trendline='ols', title=f'Weekly {AGG}: HR vs HRV')\n",
    "        fig.write_html(str(OUTDIR/'weekly_hr_vs_hrv.html'))\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4980e1",
   "metadata": {},
   "source": [
    "## 05 | Correlations (daily + weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d3d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plot(df: pd.DataFrame, title: str, outpng: Path):\n",
    "    if df.empty: return\n",
    "    corr = df.corr(method='spearman')\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.imshow(corr.values, aspect='auto')\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "    plt.colorbar(); plt.title(title); plt.tight_layout(); plt.savefig(outpng); plt.show()\n",
    "\n",
    "if not feat_cardio.empty:\n",
    "    dfnum = feat_cardio.drop(columns=['date']).select_dtypes(include=[np.number])\n",
    "    corr_plot(dfnum, 'Spearman correlation (daily cardio)', OUTDIR/'corr_daily.png')\n",
    "if not weekly.empty:\n",
    "    corr_plot(weekly, 'Spearman correlation (weekly cardio)', OUTDIR/'corr_weekly.png')\n",
    "\n",
    "# plotly interactive corr (daily)\n",
    "if not feat_cardio.empty:\n",
    "    dfnum = feat_cardio.drop(columns=['date']).select_dtypes(include=[np.number])\n",
    "    corr = dfnum.corr(method='spearman')\n",
    "    fig = px.imshow(corr, aspect='auto', title='Spearman correlation (daily cardio, interactive)')\n",
    "    fig.write_html(str(OUTDIR/'corr_daily.html'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b846d",
   "metadata": {},
   "source": [
    "## 06 | Segment analysis (S1–S6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b547a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_stats = pd.DataFrame()\n",
    "if not feat_cardio.empty and 'segment_id' in feat_cardio.columns:\n",
    "    seg_counts = feat_cardio['segment_id'].value_counts(dropna=False).sort_index()\n",
    "    print('segment counts:\\n', seg_counts)\n",
    "    seg_counts.to_csv(OUTDIR/'segments_counts.csv')\n",
    "    # primeira métrica de HR para boxplot\n",
    "    hrcols = [c for c in feat_cardio.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "    if hrcols:\n",
    "        data = [feat_cardio.loc[feat_cardio['segment_id']==sid, hrcols[0]].dropna().values for sid in sorted(feat_cardio['segment_id'].dropna().unique())]\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.boxplot(data)\n",
    "        plt.title(f'HR mean by segment ({hrcols[0]})'); plt.tight_layout(); plt.savefig(OUTDIR/'box_hr_by_segment.png'); plt.show()\n",
    "    # estatísticas agregadas por segmento\n",
    "    numcols = [c for c in feat_cardio.columns if c!='date' and pd.api.types.is_numeric_dtype(feat_cardio[c])]\n",
    "    seg_stats = feat_cardio.groupby('segment_id')[numcols].agg(['median','mean','std','count'])\n",
    "    seg_stats.to_csv(OUTDIR/'segment_stats.csv')\n",
    "    display(seg_stats.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f314ef5",
   "metadata": {},
   "source": [
    "## 07 | Label preview (if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c6a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label column found; skipping label preview.\n"
     ]
    }
   ],
   "source": [
    "label_cols = [c for c in feat_dailyu.columns if c.lower()=='label'] if not feat_dailyu.empty else []\n",
    "if label_cols:\n",
    "    df = feat_dailyu[['date', label_cols[0]]].merge(feat_cardio, on='date', how='left')\n",
    "    lab = label_cols[0]\n",
    "    print('label distribution:\\n', df[lab].value_counts(dropna=False))\n",
    "    hrcols = [c for c in feat_cardio.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "    if hrcols:\n",
    "        groups = [g.dropna().values for _, g in df.groupby(lab)[hrcols[0]]]\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.boxplot(groups)\n",
    "        plt.title(f'{hrcols[0]} by label'); plt.tight_layout(); plt.savefig(OUTDIR/'box_hr_by_label.png'); plt.show()\n",
    "else:\n",
    "    print('No label column found; skipping label preview.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ae518",
   "metadata": {},
   "source": [
    "## 08 | Export consolidated summary (JSON + XLSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb89b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: data_ai\\P000001\\snapshots\\2025-09-29\\eda_outputs\\eda_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "summ = {\n",
    "    'pid': PID,\n",
    "    'snapshot': SNAP,\n",
    "    'manifests': {\n",
    "        'extract': (extract_manifest.get('export_sha256','') if extract_manifest else ''),\n",
    "        'cardio_outputs': list((cardio_manifest.get('outputs') or {}).keys()) if cardio_manifest else [],\n",
    "    },\n",
    "    'qc': {'cardio': qc_cardio, 'dailyu': qc_dailyu},\n",
    "}\n",
    "(OUTDIR/'eda_summary.json').write_text(json.dumps(summ, indent=2), encoding='utf-8')\n",
    "\n",
    "# XLSX with multiple sheets\n",
    "xlsx_path = OUTDIR/'eda_summary.xlsx'\n",
    "with pd.ExcelWriter(xlsx_path, engine='openpyxl') as xw:\n",
    "    # QC\n",
    "    pd.DataFrame([qc_cardio]).to_excel(xw, index=False, sheet_name='qc_cardio')\n",
    "    pd.DataFrame([qc_dailyu]).to_excel(xw, index=False, sheet_name='qc_dailyu')\n",
    "    # Daily describe\n",
    "    if not feat_cardio.empty:\n",
    "        num = feat_cardio.drop(columns=['date']).select_dtypes(include=[np.number])\n",
    "        num.describe().T.to_excel(xw, sheet_name='daily_describe')\n",
    "    # Weekly\n",
    "    if not weekly.empty:\n",
    "        weekly.to_excel(xw, sheet_name='weekly')\n",
    "    # Segment stats\n",
    "    if 'seg_stats' in globals() and isinstance(seg_stats, pd.DataFrame) and not seg_stats.empty:\n",
    "        seg_stats.to_excel(xw, sheet_name='segment_stats')\n",
    "\n",
    "print('Wrote:', xlsx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fa74b8-c465-4d6a-9e8b-8205fa9913e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAPDIR = data_ai\\P000001\\snapshots\\2025-09-29\n",
      "features_cardiovascular.csv → False 0\n",
      "features_daily_updated.csv → False 0\n",
      "apple_heart_rate.csv → False 0\n",
      "apple_hrv_sdnn.csv → False 0\n",
      "apple_sleep_intervals.csv → False 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_ai\\\\P000001\\\\snapshots\\\\2025-09-29\\\\features_cardiovascular.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(f.name, \u001b[33m\"\u001b[39m\u001b[33m→\u001b[39m\u001b[33m\"\u001b[39m, f.exists(), (f.stat().st_size \u001b[38;5;28;01mif\u001b[39;00m f.exists() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m fc = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSNAPDIR\u001b[49m\u001b[43m/\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeatures_cardiovascular.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfeatures_cardiovascular shape:\u001b[39m\u001b[33m\"\u001b[39m, fc.shape)\n\u001b[32m     17\u001b[39m hr_cols  = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m fc.columns \u001b[38;5;28;01mif\u001b[39;00m re.search(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(^|_)hr_mean(_|$)\u001b[39m\u001b[33m'\u001b[39m, c)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_ai\\\\P000001\\\\snapshots\\\\2025-09-29\\\\features_cardiovascular.csv'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, re\n",
    "\n",
    "print(\"SNAPDIR =\", SNAPDIR)\n",
    "files = [\n",
    "    SNAPDIR/\"features_cardiovascular.csv\",\n",
    "    SNAPDIR/\"features_daily_updated.csv\",\n",
    "    SNAPDIR/\"per-metric\"/\"apple_heart_rate.csv\",\n",
    "    SNAPDIR/\"per-metric\"/\"apple_hrv_sdnn.csv\",\n",
    "    SNAPDIR/\"per-metric\"/\"apple_sleep_intervals.csv\",\n",
    "]\n",
    "for f in files:\n",
    "    print(f.name, \"→\", f.exists(), (f.stat().st_size if f.exists() else 0))\n",
    "\n",
    "fc = pd.read_csv(SNAPDIR/\"features_cardiovascular.csv\", parse_dates=[\"date\"])\n",
    "print(\"features_cardiovascular shape:\", fc.shape)\n",
    "hr_cols  = [c for c in fc.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "hrv_cols = [c for c in fc.columns if re.search(r'hrv.*(sdnn|sdnn_ms).*mean', c)]\n",
    "print(\"hr_cols:\", hr_cols)\n",
    "print(\"hrv_cols:\", hrv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179e0641-d3ff-41a4-9347-61e02b053777",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_ai\\\\P000001\\\\snapshots\\\\2025-09-29\\\\features_cardiovascular.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m fc = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSNAPDIR\u001b[49m\u001b[43m/\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeatures_cardiovascular.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mshape:\u001b[39m\u001b[33m\"\u001b[39m, fc.shape)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcols:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(fc.columns)[:\u001b[32m20\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\practicum2-nof1-adhd-bd\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_ai\\\\P000001\\\\snapshots\\\\2025-09-29\\\\features_cardiovascular.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re\n",
    "fc = pd.read_csv(SNAPDIR/\"features_cardiovascular.csv\", parse_dates=[\"date\"])\n",
    "print(\"shape:\", fc.shape)\n",
    "print(\"cols:\", list(fc.columns)[:20])\n",
    "hr_cols  = [c for c in fc.columns if re.search(r'(^|_)hr_mean(_|$)', c)]\n",
    "hrv_cols = [c for c in fc.columns if re.search(r'hrv.*(sdnn|sdnn_ms).*mean', c)]\n",
    "print(\"hr_cols:\", hr_cols)\n",
    "print(\"hrv_cols:\", hrv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1c957-1066-4c4a-99b2-2d1bdd8845ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
